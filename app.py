# å¯¼å…¥æ‰€éœ€çš„åº“
import streamlit as st
import pandas as pd
import numpy as np
import os
import re
import unicodedata
from PIL import Image
import io
import base64
import json
from datetime import timedelta

# --- SDK ä¾èµ–æ£€æŸ¥ (ä¿æŒä¸å˜) ---
try:
    from alibabacloud_ocr_api20210707.client import Client as OcrClient
    from alibabacloud_tea_openapi import models as open_api_models
    from alibabacloud_ocr_api20210707 import models as ocr_models
    ALIYUN_SDK_AVAILABLE = True
except ImportError:
    ALIYUN_SDK_AVAILABLE = False
    
# --- ç»Ÿä¸€çš„é¡µé¢é…ç½® ---
st.set_page_config(layout="wide", page_title="é…’åº—å·¥å…·ç®±")
st.title("ğŸ† é…’åº—å·¥å…·ç®±")

# --- ä¼šè¯çŠ¶æ€åˆå§‹åŒ– ---
# ç»Ÿä¸€ç®¡ç†æ‰€æœ‰ä¼šè¯çŠ¶æ€ï¼Œé¿å…å†²çªã€‚
if 'df1' not in st.session_state:
    st.session_state.update({
        'df1': None, 'df2': None, 'df1_name': "", 'df2_name': "",
        'ran_comparison': False, 'common_rows': pd.DataFrame(),
        'matched_df': pd.DataFrame(), 'in_file1_only': pd.DataFrame(),
        'in_file2_only': pd.DataFrame(), 'compare_cols_keys': []
    })

# --- OCR é”€å”®é€šçŸ¥ç”Ÿæˆå™¨æ‰€éœ€çš„å‡½æ•° ---
TEAM_TYPE_MAP = { "CON": "ä¼šè®®å›¢", "FIT": "æ•£å®¢å›¢", "WA": "å©šå®´å›¢" }
DEFAULT_TEAM_TYPE = "æ—…æ¸¸å›¢"
ALL_ROOM_CODES = [
    "DETN", "DKN", "DQN", "DSKN", "DSTN", "DTN", "EKN", "EKS", "ESN", "ESS",
    "ETN", "ETS", "FSN", "FSB", "FSC", "OTN", "PSA", "PSB", "RSN", "SKN",
    "SQN", "SQS", "SSN", "SSS", "STN", "STS", "JDEN", "JDKN", "JDKS", "JEKN",
    "JESN", "JESS", "JETN", "JETS", "JKN", "JLKN", "JTN", "JTS", "PSC", "PSD",
    "VCKN", "VCKD", "SITN", "JEN", "JIS", "JTIN"
]

def check_password():
    def login_form():
        with st.form("Credentials"):
            st.text_input("ç”¨æˆ·å", key="username")
            st.text_input("å¯†ç ", type="password", key="password")
            st.form_submit_button("ç™»å½•", on_click=password_entered)

    def password_entered():
        # åœ¨è¿™é‡Œæ›¿æ¢ä¸ºä½ çœŸå®çš„ç”¨æˆ·åå’Œå¯†ç 
        app_username = os.environ.get("APP_USERNAME", "testuser")
        app_password = os.environ.get("APP_PASSWORD", "testpass")
        if st.session_state["username"] == app_username and st.session_state["password"] == app_password:
            st.session_state["password_correct"] = True
            del st.session_state["password"]
            del st.session_state["username"]
        else:
            st.session_state["password_correct"] = False

    if "password_correct" in st.session_state and st.session_state["password_correct"]:
        return True

    login_form()
    if "password_correct" in st.session_state and not st.session_state.password_correct:
        st.error("ğŸ˜• ç”¨æˆ·åæˆ–å¯†ç ä¸æ­£ç¡®ã€‚")
    return False

def get_ocr_text_from_aliyun(image: Image.Image) -> str:
    if not ALIYUN_SDK_AVAILABLE:
        st.error("é”™è¯¯ï¼šé˜¿é‡Œäº‘ SDK æœªå®‰è£…ã€‚è¯·ç¡®ä¿ requirements.txt æ–‡ä»¶é…ç½®æ­£ç¡®ã€‚")
        return None
    
    # ç¤ºä¾‹å‡­è¯ï¼Œè¯·åœ¨ä½ çš„ Streamlit Secrets ä¸­é…ç½®
    if "aliyun_credentials" not in st.secrets:
        st.info("æç¤ºï¼šæœªæ‰¾åˆ°é˜¿é‡Œäº‘å‡­è¯ã€‚å°†ä½¿ç”¨æ¨¡æ‹Ÿ OCR åŠŸèƒ½ã€‚")
        return "CON2025/æå›› 09/26 18:00 09/28 12:00 JDKN 10 1000.00 ETN 5 950.00"

    try:
        creds = st.secrets["aliyun_credentials"]
        access_key_id = creds.get("access_key_id")
        access_key_secret = creds.get("access_key_secret")
        
        if not access_key_id or not access_key_secret:
            st.error("é”™è¯¯ï¼šé˜¿é‡Œäº‘ AccessKey ID æˆ– Secret æœªåœ¨ Secrets ä¸­æ­£ç¡®é…ç½®ã€‚")
            return None

        config = open_api_models.Config(
            access_key_id=access_key_id,
            access_key_secret=access_key_secret,
            endpoint='ocr-api.cn-hangzhou.aliyuncs.com'
        )
        client = OcrClient(config)
        
        buffered = io.BytesIO()
        image_format = "PNG" if image.format is None or image.format.upper() not in ["JPG", "JPEG", "BMP"] else image.format.upper()
        if image_format == "JPEG": image_format="JPG"
        image.save(buffered, format=image_format)
        buffered.seek(0)
        
        request = ocr_models.RecognizeGeneralRequest(body=buffered)
        response = client.recognize_general(request)
        
        if response.status_code == 200 and response.body and response.body.data:
            data = json.loads(response.body.data)
            return data.get('content', '')
        else:
            raise Exception(f"é˜¿é‡Œäº‘ OCR API è¿”å›é”™è¯¯: {response.body.message if response.body else 'æ— è¯¦ç»†ä¿¡æ¯'}")

    except Exception as e:
        st.error(f"è°ƒç”¨é˜¿é‡Œäº‘ OCR API å¤±è´¥: {e}")
        return None

def extract_booking_info(ocr_text: str):
    team_name_pattern = re.compile(r'((?:CON|FIT|WA)\d+\s*/\s*[\u4e00-\u9fa5\w]+)', re.IGNORECASE)
    date_pattern = re.compile(r'(\d{1,2}/\d{1,2})')
    
    team_name_match = team_name_pattern.search(ocr_text)
    if not team_name_match: return "é”™è¯¯ï¼šæ— æ³•è¯†åˆ«å‡ºå›¢é˜Ÿåç§°ã€‚"
    team_name = re.sub(r'\s*/\s*', '/', team_name_match.group(1).strip())

    all_dates = date_pattern.findall(ocr_text)
    unique_dates = sorted(list(set(all_dates)))
    if not unique_dates: return "é”™è¯¯ï¼šæ— æ³•è¯†åˆ«å‡ºæœ‰æ•ˆçš„æ—¥æœŸã€‚"
    arrival_date = unique_dates[0]
    departure_date = unique_dates[-1]

    room_codes_pattern_str = '|'.join(ALL_ROOM_CODES)
    room_finder_pattern = re.compile(f'({room_codes_pattern_str})\\s*(\\d+)', re.IGNORECASE)
    price_finder_pattern = re.compile(r'\b(\d+\.\d{2})\b')

    found_rooms = [(m.group(1).upper(), int(m.group(2)), m.span()) for m in room_finder_pattern.finditer(ocr_text)]
    found_prices = [(float(m.group(1)), m.span()) for m in price_finder_pattern.finditer(ocr_text)]
    
    room_details = []
    available_prices = list(found_prices)

    for room_type, num_rooms, room_span in found_rooms:
        best_price = None
        best_price_index = -1
        min_distance = float('inf')

        for i, (price_val, price_span) in enumerate(available_prices):
            if price_span[0] > room_span[1]:
                distance = price_span[0] - room_span[1]
                if distance < min_distance:
                    min_distance = distance
                    best_price = price_val
                    best_price_index = i
        
        if best_price is not None and best_price > 0:
            room_details.append((room_type, num_rooms, int(best_price)))
            if best_price_index != -1:
                available_prices.pop(best_price_index)

    if not room_details:
        return f"æç¤ºï¼šæ‰¾åˆ°äº†å›¢é˜Ÿ {team_name}ï¼Œä½†æœªèƒ½è‡ªåŠ¨åŒ¹é…ä»»ä½•æœ‰æ•ˆçš„æˆ¿å‹å’Œä»·æ ¼ã€‚è¯·æ£€æŸ¥åŸå§‹æ–‡æœ¬å¹¶æ‰‹åŠ¨å¡«å†™ã€‚"

    team_prefix = team_name[:3].upper()
    team_type = TEAM_TYPE_MAP.get(team_prefix, DEFAULT_TEAM_TYPE)
    room_details.sort(key=lambda x: x[1])
    
    try:
        arr_month, arr_day = map(int, arrival_date.split('/'))
        dep_month, dep_day = map(int, departure_date.split('/'))
        formatted_arrival = f"{arr_month}æœˆ{arr_day}æ—¥"
        formatted_departure = f"{dep_month}æœˆ{dep_day}æ—¥"
    except (ValueError, IndexError):
        return "é”™è¯¯ï¼šæ—¥æœŸæ ¼å¼æ— æ³•è§£æã€‚"
        
    df = pd.DataFrame(room_details, columns=['æˆ¿å‹', 'æˆ¿æ•°', 'å®šä»·'])
    return {"team_name": team_name, "team_type": team_type, "arrival_date": formatted_arrival, "departure_date": formatted_departure, "room_dataframe": df}

def format_notification_speech(team_name, team_type, arrival_date, departure_date, room_df):
    date_range_string = f"{arrival_date}è‡³{departure_date}"
    room_details = room_df.to_dict('records')
    formatted_rooms = [f"{item['æˆ¿æ•°']}é—´{item['æˆ¿å‹']}({item['å®šä»·']})" for item in room_details]
    room_string = " ".join(formatted_rooms) if formatted_rooms else "æ— æˆ¿é—´è¯¦æƒ…"
    return f"æ–°å¢{team_type} {team_name} {date_range_string} {room_string}ã€‚é”€å”®é€šçŸ¥"

# --- Excel æ¯”å¯¹æ‰€éœ€å‡½æ•° ---
def forensic_clean_text(text):
    if not isinstance(text, str): return text
    try:
        cleaned_text = unicodedata.normalize('NFKC', text)
    except (TypeError, ValueError):
        return text
    cleaned_text = re.sub(r'[\u200B-\u200D\uFEFF\s\xa0]+', '', cleaned_text)
    return cleaned_text.strip()

def process_and_standardize(df, mapping, case_insensitive=False, room_type_equivalents=None):
    if not mapping.get('name'):
        return pd.DataFrame()
    standard_df = pd.DataFrame()
    for col_key, col_name in mapping.items():
        if col_name and col_name in df.columns:
            standard_df[col_key] = df[col_name]
    def robust_date_parser(series):
        def process_date(date_str):
            if pd.isna(date_str): return pd.NaT
            date_str = str(date_str).strip()
            if re.match(r'^\d{1,2}/\d{1,2}', date_str):
                date_part = date_str.split(' ')[0]
                return f"2025-{date_part.replace('/', '-')}"
            return date_str
        return pd.to_datetime(series.apply(process_date), errors='coerce').dt.strftime('%Y-%m-%d')
    if 'start_date' in standard_df.columns:
        standard_df['start_date'] = robust_date_parser(standard_df['start_date'])
    if 'end_date' in standard_df.columns:
        standard_df['end_date'] = robust_date_parser(standard_df['end_date'])
    if 'room_type' in standard_df.columns:
        standard_df['room_type'] = standard_df['room_type'].astype(str).apply(forensic_clean_text)
        if room_type_equivalents:
            cleaned_equivalents = {forensic_clean_text(k): [forensic_clean_text(val) for val in v] for k, v in room_type_equivalents.items()}
            reverse_map = {val: key for key, values in cleaned_equivalents.items() for val in values}
            standard_df['room_type'] = standard_df['room_type'].replace(reverse_map)
    if 'price' in standard_df.columns:
        standard_df['price'] = pd.to_numeric(standard_df['price'].astype(str).str.strip(), errors='coerce')
    standard_df['name'] = standard_df['name'].astype(str).str.split(r'[ã€,ï¼Œ/]')
    standard_df = standard_df.explode('name')
    standard_df['name'] = standard_df['name'].apply(forensic_clean_text)
    if case_insensitive:
        standard_df['name'] = standard_df['name'].str.lower()
    standard_df = standard_df[standard_df['name'] != ''].dropna(subset=['name']).reset_index(drop=True)
    return standard_df

def highlight_diff(row, col1, col2):
    style = 'background-color: #FFC7CE'
    if row.get(col1) != row.get(col2) and not (pd.isna(row.get(col1)) and pd.isna(row.get(col2))):
        return [style] * len(row)
    return [''] * len(row)

# --- Excel æŠ¥å‘Šåˆ†æå™¨æ‰€éœ€å‡½æ•° (æ¨¡æ‹Ÿå‡½æ•°) ---
def analyze_reports_ultimate(file_paths):
    st.info("æ­£åœ¨ä½¿ç”¨æ¨¡æ‹Ÿåˆ†æåŠŸèƒ½ã€‚è¯·å°†æ­¤å‡½æ•°æ›¿æ¢ä¸ºä½ çš„çœŸå®é€»è¾‘ã€‚")
    summaries = [f"æ–‡ä»¶ {os.path.basename(f)} åˆ†æå®Œæˆã€‚" for f in file_paths]
    unknown_codes = {"CODE_X": 5, "CODE_Y": 2}
    return summaries, unknown_codes

# --- é…’åº—å…¥ä½æ•°æ®åˆ†ææ‰€éœ€å‡½æ•° ---
jinling_rooms = [
    'DETN', 'DKN', 'DQN', 'DQS', 'DSKN', 'DSTN', 'DTN', 'EKN', 'EKS', 'ESN', 'ESS', 'ETN', 'ETS',
    'FSB', 'FSC', 'FSN', 'OTN', 'PSA', 'PSB', 'RSN', 'SKN', 'SQN', 'SQS', 'SSN', 'SSS', 'STN', 'STS'
]
yatal_rooms = [
    'JDEN', 'JDKN', 'JDKS', 'JEKN', 'JESN', 'JESS', 'JETN', 'JETS', 'JKN', 'JLKN', 'JTN', 'JTS',
    'PSC', 'PSD', 'VCKD', 'VCKN'
]
room_to_building = {code: "é‡‘é™µæ¥¼" for code in jinling_rooms}
room_to_building.update({code: "äºšå¤ªæ¥¼" for code in yatal_rooms})

def get_building(room_code):
    """æ ¹æ®æˆ¿å‹ä»£ç è·å–æ¥¼å±‚"""
    return room_to_building.get(room_code, "å…¶ä»–æ¥¼")

# --- ä¸»åº”ç”¨å¸ƒå±€ (ä½¿ç”¨æ ‡ç­¾é¡µ) ---
tab_names = ["ğŸ¨ é…’åº—å…¥ä½æ•°æ®åˆ†æ", "ğŸ“ˆ Excel æŠ¥å‘Šåˆ†æå™¨", "ğŸ“Š å¤šç»´å®¡æ ¸æ¯”å¯¹å¹³å°", "ğŸ“‘ OCR é”€å”®é€šçŸ¥ç”Ÿæˆå™¨"]
tab1, tab2, tab3, tab4 = st.tabs(tab_names)

with tab1:
    st.title("é…’åº—å…¥ä½æ•°æ®åˆ†æåº”ç”¨")
    st.markdown("---")
    # ä¸Šä¼ æ–‡ä»¶
    uploaded_file = st.sidebar.file_uploader("ä¸Šä¼ æ‚¨çš„Excelæ–‡ä»¶", type=["xlsx", "xls"])
    if uploaded_file:
        df = pd.read_excel(uploaded_file)
        st.success("æ–‡ä»¶ä¸Šä¼ æˆåŠŸï¼")
        # é¢„å¤„ç†æ•°æ®
        df.columns = [col.upper() for col in df.columns]
        df['åˆ°è¾¾'] = pd.to_datetime(df['åˆ°è¾¾'], errors='coerce').dt.date
        df['ç¦»å¼€'] = pd.to_datetime(df['ç¦»å¼€'], errors='coerce').dt.date
        # æ¸…æ´—æ•°æ®ï¼Œåˆ é™¤åˆ°è¾¾æˆ–ç¦»å¼€æ—¥æœŸä¸ºç©ºçš„è¡Œ
        df.dropna(subset=['åˆ°è¾¾', 'ç¦»å¼€'], inplace=True)
        df = df[df['æˆ¿å‹ä»£ç '].isin(jinling_rooms + yatal_rooms)]
        df['æ¥¼å±‚'] = df['æˆ¿å‹ä»£ç '].apply(get_building)
        # 1. åˆ°åº—æˆ¿æ•°ç»Ÿè®¡
        st.header("1. åˆ°åº—æˆ¿æ•°ç»Ÿè®¡")
        st.write("---")
        arrival_date_col = 'åˆ°è¾¾'  # ä½ çš„æ•°æ®ä¸­ä»£è¡¨åˆ°è¾¾æ—¥æœŸçš„åˆ—å
        status_col = 'çŠ¶æ€'       # ä½ çš„æ•°æ®ä¸­ä»£è¡¨çŠ¶æ€çš„åˆ—å
        room_count_col = 'æˆ¿é—´æ•°'   # ä½ çš„æ•°æ®ä¸­ä»£è¡¨æˆ¿é—´æ•°çš„åˆ—å
        unique_arrival_dates = sorted(df[arrival_date_col].unique())
        selected_date = st.date_input("é€‰æ‹©ä¸€ä¸ªæ—¥æœŸæŸ¥çœ‹å½“å¤©çš„åˆ°åº—æˆ¿æ•°", value=unique_arrival_dates[0] if unique_arrival_dates else None)
        if selected_date:
            # ç­›é€‰å‡ºç¬¦åˆæ¡ä»¶çš„åˆ°åº—æ•°æ® (çŠ¶æ€ä¸ºRï¼Œåˆ°è¾¾æ—¥æœŸä¸ºé€‰æ‹©æ—¥æœŸ)
            arrival_df = df[(df[status_col] == 'R') & (df[arrival_date_col] == selected_date)]
            # æŒ‰æ¥¼å±‚ç»Ÿè®¡æˆ¿é—´æ•°
            arrival_by_building = arrival_df.groupby('æ¥¼å±‚')[room_count_col].sum().reset_index()
            st.subheader(f"åˆ°åº—æ—¥æœŸï¼š{selected_date}ï¼ŒçŠ¶æ€ï¼šR")
            if not arrival_by_building.empty:
                jinling_count = arrival_by_building[arrival_by_building['æ¥¼å±‚'] == 'é‡‘é™µæ¥¼'][room_count_col].sum()
                yatal_count = arrival_by_building[arrival_by_building['æ¥¼å±‚'] == 'äºšå¤ªæ¥¼'][room_count_col].sum()
                st.info(f"é‡‘é™µæ¥¼åˆ°åº—æˆ¿æ•°: **{jinling_count}**")
                st.info(f"äºšå¤ªæ¥¼åˆ°åº—æˆ¿æ•°: **{yatal_count}**")
            else:
                st.warning("æ‰€é€‰æ—¥æœŸæ²¡æœ‰åˆ°åº—æ•°æ®ã€‚")
        st.markdown("---")
        # 2. ä½åº—æ—¥ç­›é€‰
        st.header("2. ä½åº—æ—¥ç­›é€‰")
        st.write("---")
        # ä½åº—æ—¥ç­›é€‰å™¨
        stay_dates_min = df['åˆ°è¾¾'].min()
        stay_dates_max = df['ç¦»å¼€'].max()
        stay_date_range = st.date_input(
            "é€‰æ‹©ä½åº—æ—¥èŒƒå›´",
            value=(stay_dates_min, stay_dates_max) if stay_dates_min and stay_dates_max else None
        )
        if stay_date_range and len(stay_date_range) == 2:
            start_date, end_date = stay_date_range
            # æˆ¿ä»·èŒƒå›´ç­›é€‰å™¨
            price_col = 'æˆ¿ä»·' # ä½ çš„æ•°æ®ä¸­ä»£è¡¨æˆ¿ä»·çš„åˆ—å
            min_price = int(df[price_col].min()) if not df[price_col].isnull().all() else 0
            max_price = int(df[price_col].max()) if not df[price_col].isnull().all() else 1000
            price_range = st.slider(
                "é€‰æ‹©æˆ¿ä»·èŒƒå›´",
                min_value=min_price,
                max_value=max_price,
                value=(min_price, max_price),
                step=10
            )
            # å¸‚åœºç å¤šé€‰ç­›é€‰å™¨
            market_code_col = 'å¸‚åœºç ' # ä½ çš„æ•°æ®ä¸­ä»£è¡¨å¸‚åœºç çš„åˆ—å
            unique_market_codes = df[market_code_col].unique().tolist()
            selected_market_codes = st.multiselect(
                "é€‰æ‹©å¸‚åœºç ",
                options=unique_market_codes,
                default=unique_market_codes
            )
            # æ ¹æ®ä½åº—æ—¥ã€æˆ¿ä»·å’Œå¸‚åœºç è¿›è¡Œç­›é€‰
            filtered_df_list = []
            for index, row in df.iterrows():
                arrival = row['åˆ°è¾¾']
                departure = row['ç¦»å¼€']
                # è®¡ç®—ä½åº—æœŸé—´çš„æ¯ä¸€å¤©
                current_date = arrival
                while current_date < departure:
                    if start_date <= current_date <= end_date:
                        # å¦‚æœè¯¥è¡Œæ•°æ®ç¬¦åˆæˆ¿ä»·å’Œå¸‚åœºç ç­›é€‰æ¡ä»¶ï¼Œä¸”åœ¨ä½åº—æ—¥æœŸèŒƒå›´å†…ï¼Œåˆ™æ·»åŠ 
                        if price_range[0] <= row[price_col] <= price_range[1] and row[market_code_col] in selected_market_codes:
                            filtered_df_list.append({
                                'è®¢å•å·': row['è®¢å•å·'],
                                'ä½åº—æ—¥': current_date,
                                'æˆ¿ä»·': row['æˆ¿ä»·'],
                                'å¸‚åœºç ': row['å¸‚åœºç '],
                                'æˆ¿é—´æ•°': row['æˆ¿é—´æ•°']
                            })
                    current_date += timedelta(days=1)
            if filtered_df_list:
                filtered_df = pd.DataFrame(filtered_df_list)
                # ç»Ÿè®¡å…·ä½“çš„å¯¹åº”æˆ¿æ•°
                total_rooms = filtered_df['æˆ¿é—´æ•°'].sum()
                st.subheader(f"ç­›é€‰ç»“æœ ({start_date} è‡³ {end_date})")
                st.success(f"ç¬¦åˆç­›é€‰æ¡ä»¶çš„æˆ¿é—´æ€»æ•°: **{total_rooms}**")
                st.markdown("### è¯¦ç»†æ•°æ®")
                st.dataframe(filtered_df)
            else:
                st.warning("æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆç­›é€‰æ¡ä»¶çš„æ•°æ®ã€‚")
    else:
        st.info("è¯·åœ¨å·¦ä¾§è¾¹æ ä¸Šä¼ æ‚¨çš„Excelæ–‡ä»¶ä»¥å¼€å§‹åˆ†æã€‚")

with tab2:
    st.title("ğŸ“ˆ Excel æŠ¥å‘Šåˆ†æå™¨")
    st.markdown("---ä¼¯çˆµé…’åº—å›¢é˜ŸæŠ¥è¡¨åˆ†æå·¥å…·---")
    uploaded_files = st.file_uploader("è¯·ä¸Šä¼ æ‚¨çš„ Excel æŠ¥å‘Šæ–‡ä»¶ (.xlsx)", type=["xlsx"], accept_multiple_files=True)
    if uploaded_files:
        st.subheader("åˆ†æç»“æœ")
        temp_dir = "./temp_uploaded_files"
        os.makedirs(temp_dir, exist_ok=True)
        file_paths = []
        for uploaded_file in uploaded_files:
            temp_file_path = os.path.join(temp_dir, uploaded_file.name)
            with open(temp_file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            file_paths.append(temp_file_path)
        desired_order = ["æ¬¡æ—¥åˆ°è¾¾", "æ¬¡æ—¥åœ¨ä½", "æ¬¡æ—¥ç¦»åº—", "åå¤©åˆ°è¾¾"]
        def sort_key(file_path):
            file_name = os.path.basename(file_path)
            for i, keyword in enumerate(desired_order):
                if keyword in file_name:
                    return i
            return len(desired_order)
        file_paths.sort(key=sort_key)
        if st.button("å¼€å§‹åˆ†æ"):
            with st.spinner("æ­£åœ¨åˆ†æä¸­ï¼Œè¯·ç¨å€™..."):
                summaries, unknown_codes = analyze_reports_ultimate(file_paths)
            for summary in summaries:
                st.write(summary)
            if unknown_codes:
                st.subheader("ä¾¦æµ‹åˆ°çš„æœªçŸ¥æˆ¿å‹ä»£ç  (è¯·æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°è§„åˆ™)")
                for code, count in unknown_codes.items():
                    st.write(f"ä»£ç : '{code}' (å‡ºç°äº† {count} æ¬¡)")
            for f_path in file_paths:
                os.remove(f_path)
            os.rmdir(temp_dir)
    else:
        st.info("è¯·ä¸Šä¼ ä¸€ä¸ªæˆ–å¤šä¸ª Excel æ–‡ä»¶ä»¥å¼€å§‹åˆ†æã€‚")
    st.markdown("""
    ---
    #### ä½¿ç”¨è¯´æ˜ï¼š
    1. ç‚¹å‡» "Browse files" ä¸Šä¼ æ‚¨çš„ Excel æŠ¥å‘Šã€‚
    2. æ–‡ä»¶ä¸Šä¼ åï¼Œç‚¹å‡» "å¼€å§‹åˆ†æ" æŒ‰é’®ã€‚
    3. åˆ†æç»“æœå°†æ˜¾ç¤ºåœ¨ä¸‹æ–¹ã€‚
    """)

with tab3:
    st.title("å¤šç»´å®¡æ ¸æ¯”å¯¹å¹³å° V23.2 ğŸ† (ç»ˆææ™ºèƒ½æ—¥æœŸç‰ˆ)")
    st.info("å…¨æ–°æ¨¡å¼ï¼šç»“æœä»¥ç‹¬ç«‹çš„æ ‡ç­¾é¡µå±•ç¤ºï¼Œå¹¶å†…ç½®æ™ºèƒ½æ—¥æœŸç»Ÿä¸€å¼•æ“ï¼Œæ¯”å¯¹æ›´ç²¾å‡†ï¼")
    st.header("ç¬¬ 1 æ­¥: ä¸Šä¼ æ–‡ä»¶")
    if st.button("ğŸ”„ æ¸…ç©ºå¹¶é‡ç½®", key="reset_tab2"):
        st.session_state.clear()
        st.rerun()
    col1, col2 = st.columns(2)
    with col1:
        uploaded_file1 = st.file_uploader("ä¸Šä¼ åå•æ–‡ä»¶ 1", type=['csv', 'xlsx'])
        if uploaded_file1:
            st.session_state.df1 = pd.read_excel(uploaded_file1) if uploaded_file1.name.endswith('xlsx') else pd.read_csv(uploaded_file1)
            st.session_state.df1_name = uploaded_file1.name
    with col2:
        uploaded_file2 = st.file_uploader("ä¸Šä¼ åå•æ–‡ä»¶ 2", type=['csv', 'xlsx'])
        if uploaded_file2:
            st.session_state.df2 = pd.read_excel(uploaded_file2) if uploaded_file2.name.endswith('xlsx') else pd.read_csv(uploaded_file2)
            st.session_state.df2_name = uploaded_file2.name
    if st.session_state.df1 is not None and st.session_state.df2 is not None:
        st.header("ç¬¬ 2 æ­¥: é€‰æ‹©è¦æ¯”å¯¹çš„åˆ— (å§“åå¿…é€‰)")
        mapping = {'file1': {}, 'file2': {}}
        cols_to_map = ['name', 'start_date', 'end_date', 'room_type', 'price']
        col_names_zh = ['å§“å', 'å…¥ä½æ—¥æœŸ', 'ç¦»å¼€æ—¥æœŸ', 'æˆ¿å‹', 'æˆ¿ä»·']
        cols1, cols2 = st.columns(2)
        with cols1:
            st.subheader(f"æ–‡ä»¶ 1: {st.session_state.df1_name}")
            df1_cols = [None] + list(st.session_state.df1.columns)
            for key, name_zh in zip(cols_to_map, col_names_zh):
                mapping['file1'][key] = st.selectbox(f"{name_zh}", df1_cols, key=f'f1_{key}')
        with cols2:
            st.subheader(f"æ–‡ä»¶ 2: {st.session_state.df2_name}")
            df2_cols = [None] + list(st.session_state.df2.columns)
            for key, name_zh in zip(cols_to_map, col_names_zh):
                mapping['file2'][key] = st.selectbox(f"{name_zh}", df2_cols, key=f'f2_{key}')
        st.header("ç¬¬ 3 æ­¥: é…ç½®ä¸æ‰§è¡Œ")
        room_type_equivalents = {}
        if mapping['file1'].get('room_type') and mapping['file2'].get('room_type'):
            with st.expander("â­ é«˜çº§åŠŸèƒ½ï¼šç»Ÿä¸€ä¸åŒåç§°çš„æˆ¿å‹"):
                unique_rooms1 = st.session_state.df1[mapping['file1']['room_type']].dropna().astype(str).unique()
                unique_rooms2 = list(st.session_state.df2[mapping['file2']['room_type']].dropna().astype(str).unique())
                for room1 in unique_rooms1:
                    room_type_equivalents[room1] = st.multiselect(f"æ–‡ä»¶1çš„â€œ{room1}â€ç­‰åŒäº:", unique_rooms2, key=f"map_{room1}")
        case_insensitive = st.checkbox("æ¯”å¯¹å§“åæ—¶å¿½ç•¥å¤§å°å†™/å…¨åŠè§’", True)
        if st.button("ğŸš€ å¼€å§‹æ¯”å¯¹", type="primary"):
            if not mapping['file1'].get('name') or not mapping['file2'].get('name'):
                st.error("è¯·ç¡®ä¿ä¸¤è¾¹æ–‡ä»¶çš„â€œå§“åâ€éƒ½å·²æ­£ç¡®é€‰æ‹©ã€‚")
            else:
                with st.spinner('æ­£åœ¨æ‰§è¡Œç»ˆææ¯”å¯¹...'):
                    st.session_state.ran_comparison = True
                    st.session_state.df1.sort_values(by=mapping['file1']['name'], inplace=True, ignore_index=True)
                    st.session_state.df2.sort_values(by=mapping['file2']['name'], inplace=True, ignore_index=True)
                    std_df1 = process_and_standardize(st.session_state.df1, mapping['file1'], case_insensitive, room_type_equivalents)
                    std_df2 = process_and_standardize(st.session_state.df2, mapping['file2'], case_insensitive)
                    merged_df = pd.merge(std_df1, std_df2, on='name', how='outer', suffixes=('_1', '_2'))
                    cols1_for_check = [f"{c}_1" for c in std_df1.columns if c != 'name']
                    cols2_for_check = [f"{c}_2" for c in std_df2.columns if c != 'name']
                    both_exist_mask = merged_df[cols1_for_check].notna().any(axis=1) & merged_df[cols2_for_check].notna().any(axis=1)
                    st.session_state.common_rows = merged_df[both_exist_mask].copy().reset_index(drop=True)
                    only_in_1_mask = merged_df[cols1_for_check].notna().any(axis=1) & merged_df[cols2_for_check].isna().all(axis=1)
                    st.session_state.in_file1_only = merged_df[only_in_1_mask].reset_index(drop=True)
                    only_in_2_mask = merged_df[cols1_for_check].isna().all(axis=1) & merged_df[cols2_for_check].notna().any(axis=1)
                    st.session_state.in_file2_only = merged_df[only_in_2_mask].reset_index(drop=True)
                    st.session_state.compare_cols_keys = [key for key in ['start_date', 'end_date', 'room_type', 'price'] if mapping['file1'].get(key) and mapping['file2'].get(key)]
                    if not st.session_state.common_rows.empty and st.session_state.compare_cols_keys:
                        condition = pd.Series(True, index=st.session_state.common_rows.index)
                        for key in st.session_state.compare_cols_keys:
                            condition &= (st.session_state.common_rows[f'{key}_1'] == st.session_state.common_rows[f'{key}_2']) | (st.session_state.common_rows[f'{key}_1'].isna() & st.session_state.common_rows[f'{key}_2'].isna())
                        st.session_state.matched_df = st.session_state.common_rows[condition]
                    else:
                        st.session_state.matched_df = st.session_state.common_rows
        if st.session_state.ran_comparison:
            st.header("ç¬¬ 4 æ­¥: æŸ¥çœ‹æ¯”å¯¹ç»“æœ")
            tab_list = ["ğŸ“Š ç»“æœæ€»è§ˆ"]
            tab_name_map = {'start_date': "ğŸ•µï¸ å…¥ä½æ—¥æœŸ", 'end_date': "ğŸ•µï¸ ç¦»å¼€æ—¥æœŸ", 'room_type': "ğŸ•µï¸ æˆ¿å‹", 'price': "ğŸ•µï¸ æˆ¿ä»·"}
            for key in st.session_state.compare_cols_keys:
                tab_list.append(tab_name_map[key])
            tabs = st.tabs(tab_list)
            with tabs[0]:
                st.subheader("å®è§‚ç»Ÿè®¡")
                stat_cols = st.columns(3)
                matched_count = len(st.session_state.matched_df)
                only_1_count = len(st.session_state.in_file1_only)
                only_2_count = len(st.session_state.in_file2_only)
                stat_cols[0].metric("âœ… ä¿¡æ¯å®Œå…¨ä¸€è‡´", matched_count)
                stat_cols[1].metric(f"â“ ä»… '{st.session_state.df1_name}' æœ‰", only_1_count)
                stat_cols[2].metric(f"â“ ä»… '{st.session_state.df2_name}' æœ‰", only_2_count)
                st.subheader("äººå‘˜åå•è¯¦æƒ…")
                with st.expander(f"âœ… æŸ¥çœ‹ {matched_count} æ¡ä¿¡æ¯å®Œå…¨ä¸€è‡´çš„åå•"):
                    if not st.session_state.matched_df.empty:
                        st.dataframe(st.session_state.matched_df[['name']].rename(columns={'name': 'å§“å'}))
                    else:
                        st.write("æ²¡æœ‰ä¿¡æ¯å®Œå…¨ä¸€è‡´çš„äººå‘˜ã€‚")
                with st.expander(f"â“ æŸ¥çœ‹ {only_1_count} æ¡ä»…å­˜åœ¨äº '{st.session_state.df1_name}' çš„åå•"):
                    if not st.session_state.in_file1_only.empty:
                        display_cols_1 = [c for c in cols_to_map if f"{c}_1" in st.session_state.in_file1_only.columns]
                        display_df_1 = st.session_state.in_file1_only[[f"{c}_1" for c in display_cols_1]]
                        display_df_1.columns = [col_names_zh[cols_to_map.index(c)] for c in display_cols_1]
                        st.dataframe(display_df_1)
                    else:
                        st.write("æ²¡æœ‰äººå‘˜ã€‚")
                with st.expander(f"â“ æŸ¥çœ‹ {only_2_count} æ¡ä»…å­˜åœ¨äº '{st.session_state.df2_name}' çš„åå•"):
                    if not st.session_state.in_file2_only.empty:
                        display_cols_2 = [c for c in cols_to_map if f"{c}_2" in st.session_state.in_file2_only.columns]
                        display_df_2 = st.session_state.in_file2_only[[f"{c}_2" for c in display_cols_2]]
                        display_df_2.columns = [col_names_zh[cols_to_map.index(c)] for c in display_cols_2]
                        st.dataframe(display_df_2)
                    else:
                        st.write("æ²¡æœ‰äººå‘˜ã€‚")
            for i, key in enumerate(st.session_state.compare_cols_keys):
                with tabs[i+1]:
                    col1_name, col2_name = f'{key}_1', f'{key}_2'
                    display_name = col_names_zh[cols_to_map.index(key)]
                    st.subheader(f"ã€{display_name}ã€‘æ¯”å¯¹è¯¦æƒ…")
                    if not st.session_state.common_rows.empty:
                        compare_df = st.session_state.common_rows[['name', col1_name, col2_name]].copy()
                        compare_df.rename(columns={'name': 'å§“å', col1_name: f'æ–‡ä»¶1 - {display_name}', col2_name: f'æ–‡ä»¶2 - {display_name}'}, inplace=True)
                        styled_df = compare_df.style.apply(highlight_diff, col1=f'æ–‡ä»¶1 - {display_name}', col2=f'æ–‡ä»¶2 - {display_name}', axis=1)
                        st.dataframe(styled_df)
                    else:
                        st.info("ä¸¤ä¸ªæ–‡ä»¶ä¸­æ²¡æœ‰å…±åŒçš„äººå‘˜å¯ä¾›è¿›è¡Œç»†èŠ‚æ¯”å¯¹ã€‚")
        st.divider()
        st.header("åŸå§‹æ•°æ®é¢„è§ˆ (ç‚¹å‡»æ¯”å¯¹åä¼šæŒ‰å§“åæ’åº)")
        c1, c2 = st.columns(2)
        with c1:
            st.caption(f"æ–‡ä»¶ 1: {st.session_state.df1_name}")
            st.dataframe(st.session_state.df1)
        with c2:
            st.caption(f"æ–‡ä»¶ 2: {st.session_state.df2_name}")
            st.dataframe(st.session_state.df2)

with tab4:
    st.title("ğŸ“‘ OCR é”€å”®é€šçŸ¥ç”Ÿæˆå™¨")
    if check_password():
        st.markdown("""
        **å…¨æ–°å·¥ä½œæµ**ï¼š
        1.  **ä¸Šä¼ å›¾ç‰‡ï¼Œç‚¹å‡»æå–**ï¼šç¨‹åºå°†è°ƒç”¨é˜¿é‡Œäº‘ OCR å¹¶å°†**åŸå§‹è¯†åˆ«æ–‡æœ¬**æ˜¾ç¤ºåœ¨ä¸‹æ–¹ã€‚
        2.  **è‡ªåŠ¨å¡«å……ä¸äººå·¥ä¿®æ­£**ï¼šç¨‹åºä¼šå°è¯•è‡ªåŠ¨å¡«å……ç»“æ„åŒ–ä¿¡æ¯ã€‚æ‚¨å¯ä»¥**å‚ç…§åŸå§‹æ–‡æœ¬**ï¼Œç›´æ¥åœ¨è¡¨æ ¼ä¸­ä¿®æ”¹ï¼Œç¡®ä¿ä¿¡æ¯å®Œå…¨å‡†ç¡®ã€‚
        3.  **ç”Ÿæˆè¯æœ¯**ï¼šç¡®è®¤æ— è¯¯åï¼Œç”Ÿæˆæœ€ç»ˆè¯æœ¯ã€‚
        """)
        uploaded_file = st.file_uploader("ä¸Šä¼ å›¾ç‰‡æ–‡ä»¶", type=["png", "jpg", "jpeg", "bmp"])
        if uploaded_file is not None:
            image = Image.open(uploaded_file)
            st.image(image, caption="ä¸Šä¼ çš„å›¾ç‰‡", width=300)
            if st.button("1. ä»å›¾ç‰‡æå–ä¿¡æ¯ (é˜¿é‡Œäº‘ OCR)"):
                st.session_state.clear()
                with st.spinner('æ­£åœ¨è°ƒç”¨é˜¿é‡Œäº‘ OCR API è¯†åˆ«ä¸­...'):
                    ocr_text = get_ocr_text_from_aliyun(image)
                    if ocr_text:
                        st.session_state['raw_ocr_text'] = ocr_text
                        result = extract_booking_info(ocr_text)
                        if isinstance(result, str):
                            st.warning(f"è‡ªåŠ¨è§£ææç¤ºï¼š{result}")
                            st.info("è¯·å‚è€ƒä¸‹æ–¹è¯†åˆ«å‡ºçš„åŸå§‹æ–‡æœ¬ï¼Œæ‰‹åŠ¨å¡«å†™ä¿¡æ¯ã€‚")
                            empty_df = pd.DataFrame(columns=['æˆ¿å‹', 'æˆ¿æ•°', 'å®šä»·'])
                            st.session_state['booking_info'] = { "team_name": "", "team_type": DEFAULT_TEAM_TYPE, "arrival_date": "", "departure_date": "", "room_dataframe": empty_df }
                        else:
                            st.session_state['booking_info'] = result
                            st.success("ä¿¡æ¯æå–æˆåŠŸï¼è¯·åœ¨ä¸‹æ–¹æ ¸å¯¹å¹¶ç¼–è¾‘ã€‚")
        if 'booking_info' in st.session_state:
            info = st.session_state['booking_info']
            if 'raw_ocr_text' in st.session_state:
                st.markdown("---")
                st.subheader("åŸå§‹è¯†åˆ«ç»“æœ (ä¾›å‚è€ƒ)")
                st.text_area("æ‚¨å¯ä»¥ä»è¿™é‡Œå¤åˆ¶å†…å®¹æ¥ä¿®æ­£ä¸‹é¢çš„è¡¨æ ¼", st.session_state['raw_ocr_text'], height=200)
            st.markdown("---")
            st.subheader("æ ¸å¯¹ä¸ç¼–è¾‘ä¿¡æ¯")
            col1, col2, col3, col4 = st.columns(4)
            with col1: info['team_name'] = st.text_input("å›¢é˜Ÿåç§°", value=info['team_name'])
            with col2: info['team_type'] = st.selectbox("å›¢é˜Ÿç±»å‹", options=list(TEAM_TYPE_MAP.values()) + [DEFAULT_TEAM_TYPE], index=(list(TEAM_TYPE_MAP.values()) + [DEFAULT_TEAM_TYPE]).index(info['team_type']))
            with col3: arrival = st.text_input("åˆ°è¾¾æ—¥æœŸ", value=info['arrival_date'])
            with col4: departure = st.text_input("ç¦»å¼€æ—¥æœŸ", value=info['departure_date'])
            st.markdown("##### æˆ¿é—´è¯¦æƒ… (å¯ç›´æ¥åœ¨è¡¨æ ¼ä¸­ç¼–è¾‘)")
            edited_df = st.data_editor(info['room_dataframe'], num_rows="dynamic", use_container_width=True)
            if st.button("âœ… ç”Ÿæˆæœ€ç»ˆè¯æœ¯"):
                final_speech = format_notification_speech(info['team_name'], info['team_type'], arrival, departure, edited_df)
                st.subheader("ğŸ‰ ç”ŸæˆæˆåŠŸï¼")
                st.success(final_speech)
                st.code(final_speech, language=None)
