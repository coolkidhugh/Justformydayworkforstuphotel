import re
import streamlit as st
from PIL import Image
import pandas as pd
import io
import json
import unicodedata
import os
import traceback
from datetime import timedelta, date
from collections import Counter
from streamlit_option_menu import option_menu

# --- SDK ä¾èµ– ---
try:
    from alibabacloud_ocr_api20210707.client import Client as OcrClient
    from alibabacloud_tea_openapi import models as open_api_models
    from alibabacloud_ocr_api20210707 import models as ocr_models
    from alibabacloud_tea_util import models as util_models
    ALIYUN_SDK_AVAILABLE = True
except ImportError:
    ALIYUN_SDK_AVAILABLE = False

# ==============================================================================
# --- [æ ¸å¿ƒåˆ†æé€»è¾‘] çœŸå®åˆ†æå‡½æ•° ---
# ==============================================================================
def analyze_reports_ultimate(file_paths):
    """
    æ™ºèƒ½è§£æå¹¶åŠ¨æ€å®šä½åˆ—ï¼Œå¯¹åŒ…å«å¤šä¸ªå›¢é˜Ÿçš„ExcelæŠ¥å‘Šè¿›è¡Œè¯¦ç»†ç»Ÿè®¡ã€‚
    """
    # --- æ¥¼æ ‹æˆ¿å‹ä»£ç è§„åˆ™ ---
    jinling_room_types = [
        'DETN', 'DKN', 'DKS', 'DQN', 'DQS', 'DSKN', 'DSTN', 'DTN',
        'EKN', 'EKS', 'ESN', 'ESS', 'ETN', 'ETS', 'FSB', 'FSC', 'FSN',
        'STN', 'STS', 'SKN', 'RSN', 'SQS', 'SQN'
    ]
    yatai_room_types = [
        'JDEN', 'JDKN', 'JDKS', 'JEKN', 'JESN', 'JESS', 'JETN', 'JETS',
        'JKN', 'JLKN', 'JTN', 'JTS', 'VCKD', 'VCKN'
    ]
    # --- è§„åˆ™ç»“æŸ ---

    unknown_codes_collection = Counter()
    final_summary_lines = []

    if not file_paths:
        return ["æœªä¸Šä¼ ä»»ä½•æ–‡ä»¶è¿›è¡Œåˆ†æã€‚"], unknown_codes_collection
    
    for file_path in file_paths:
        file_base_name = os.path.splitext(os.path.basename(file_path))[0]
        try:
            df_raw = pd.read_excel(file_path, header=None, dtype=str)
            all_bookings = []
            current_group_name = "æœªçŸ¥å›¢é˜Ÿ"
            current_market_code = "æ— "
            column_map = {}
            header_row_index = -1

            for index, row in df_raw.iterrows():
                row_str = ' '.join(str(cell).strip() for cell in row.dropna() if str(cell).strip())
                if not row_str:
                    continue

                if 'å›¢ä½“åç§°:' in row_str:
                    match = re.search(r'å›¢ä½“åç§°:\s*(.*?)(?:\s*å¸‚åœºç ï¼š|$)', row_str)
                    if match:
                        current_group_name = match.group(1).strip()
                    else:
                        current_group_name = "æœªçŸ¥å›¢é˜Ÿ(è§£æå¤±è´¥)"
                        
                    column_map, header_row_index, current_market_code = {}, -1, "æ— "
                    
                    market_match = re.search(r'å¸‚åœºç ï¼š\s*([\w-]+)', row_str)
                    if market_match:
                        current_market_code = market_match.group(1).strip()
                    continue
                
                if 'å›¢ä½“/å•ä½/æ—…è¡Œç¤¾/è®¢æˆ¿ä¸­å¿ƒï¼š' in row_str:
                    desc_match = re.search(r'å›¢ä½“/å•ä½/æ—…è¡Œç¤¾/è®¢æˆ¿ä¸­å¿ƒï¼š(.*)', row_str)
                    if desc_match and desc_match.group(1):
                        current_group_name += " " + desc_match.group(1).strip()
                    continue

                if 'å¸‚åœºç ï¼š' in row_str and not 'å›¢ä½“åç§°:' in row_str:
                    match = re.search(r'å¸‚åœºç ï¼š\s*([\w-]+)', row_str)
                    if match:
                        current_market_code = match.group(1).strip()
                    continue

                if 'æˆ¿å·' in row_str and 'å§“å' in row_str and 'äººæ•°' in row_str:
                    header_row_index = index
                    for i, col in enumerate(row):
                        if pd.notna(col):
                            column_map[re.sub(r'\s+', '', str(col))] = i
                    continue

                if header_row_index != -1 and index > header_row_index and not row.dropna().empty:
                    if 'å°è®¡' not in row_str:
                        all_bookings.append({'å›¢é˜Ÿåç§°': current_group_name, 'å¸‚åœºç ': current_market_code, 'data': row})
            
            if not all_bookings:
                final_summary_lines.append(f"ã€{file_base_name}ã€‘: æœªè§£æåˆ°æœ‰æ•ˆé¢„è®¢æ•°æ®è¡Œã€‚æ€»æˆ¿æ•° 0 é—´ (å…± 0 äºº)ï¼Œ(æ— ä¼šè®®/å…¬å¸å›¢é˜Ÿæˆ¿). | (æ— GTOæ—…è¡Œç¤¾æˆ¿).")
                continue 

            processed_rows = []
            for item in all_bookings:
                row_data = item['data']
                processed_row = {'å›¢é˜Ÿåç§°': item['å›¢é˜Ÿåç§°'], 'å¸‚åœºç ': item['å¸‚åœºç ']}
                for col_name, col_index in column_map.items():
                    processed_row[col_name] = row_data.get(col_index)
                processed_rows.append(processed_row)
            df = pd.DataFrame(processed_rows)

            df['çŠ¶æ€'] = df['çŠ¶æ€'].astype(str).str.strip()
            df['å¸‚åœºç '] = df['å¸‚åœºç '].astype(str).str.strip()
            
            if 'åœ¨ä½' in file_base_name:
                valid_statuses = ['R', 'I']
            elif 'ç¦»åº—' in file_base_name or 'æ¬¡æ—¥ç¦»åº—' in file_base_name or 'åå¤©' in file_base_name:
                valid_statuses = ['I', 'R', 'O']
            else:
                valid_statuses = ['R']
            
            df_active = df[df['çŠ¶æ€'].isin(valid_statuses)].copy()

            df_counted = df_active.copy()

            df_counted['æˆ¿æ•°'] = pd.to_numeric(df_counted['æˆ¿æ•°'], errors='coerce').fillna(0)
            df_counted['äººæ•°'] = pd.to_numeric(df_counted['äººæ•°'], errors='coerce').fillna(0)
            df_counted['æˆ¿ç±»'] = df_counted['æˆ¿ç±»'].astype(str).str.strip()

            total_rooms = int(df_counted['æˆ¿æ•°'].sum())
            total_guests = int(df_counted['äººæ•°'].sum())

            def assign_building(room_type):
                if room_type in yatai_room_types: return 'äºšå¤ªæ¥¼'
                elif room_type in jinling_room_types: return 'é‡‘é™µæ¥¼'
                else:
                    if room_type and room_type.lower() != 'nan':
                        unknown_codes_collection.update([room_type])
                    return 'å…¶ä»–æ¥¼'
            df_counted['å‡†ç¡®æ¥¼æ ‹'] = df_counted['æˆ¿ç±»'].apply(assign_building)

            meeting_df = df_counted[
                df_counted['å¸‚åœºç '].str.startswith('MGM', na=False) | 
                df_counted['å¸‚åœºç '].str.startswith('MTC', na=False)
            ].copy()
            
            meeting_group_count = int(meeting_df['å›¢é˜Ÿåç§°'].nunique())
            total_meeting_rooms = int(meeting_df['æˆ¿æ•°'].sum())
            meeting_jinling_rooms = int(meeting_df[meeting_df['å‡†ç¡®æ¥¼æ ‹'] == 'é‡‘é™µæ¥¼']['æˆ¿æ•°'].sum())
            meeting_yatai_rooms = int(meeting_df[meeting_df['å‡†ç¡®æ¥¼æ ‹'] == 'äºšå¤ªæ¥¼']['æˆ¿æ•°'].sum())
            meeting_other_rooms = int(meeting_df[meeting_df['å‡†ç¡®æ¥¼æ ‹'] == 'å…¶ä»–æ¥¼']['æˆ¿æ•°'].sum())

            gto_df = df_counted[df_counted['å¸‚åœºç '].str.startswith('GTO', na=False)].copy()
            gto_group_count = int(gto_df['å›¢é˜Ÿåç§°'].nunique())
            total_gto_rooms = int(gto_df['æˆ¿æ•°'].sum())
            total_gto_guests = int(gto_df['äººæ•°'].sum())
            gto_jinling_rooms = int(gto_df[gto_df['å‡†ç¡®æ¥¼æ ‹'] == 'é‡‘é™µæ¥¼']['æˆ¿æ•°'].sum())
            gto_yatai_rooms = int(gto_df[gto_df['å‡†ç¡®æ¥¼æ ‹'] == 'äºšå¤ªæ¥¼']['æˆ¿æ•°'].sum())
            gto_other_rooms = int(gto_df[gto_df['å‡†ç¡®æ¥¼æ ‹'] == 'å…¶ä»–æ¥¼']['æˆ¿æ•°'].sum())

            summary_parts = [f"ã€{file_base_name}ã€‘: æœ‰æ•ˆæ€»æˆ¿æ•° {total_rooms} é—´ (å…± {total_guests} äºº)"]

            if meeting_group_count > 0:
                meeting_report = f"ä¼šè®®/å…¬å¸å›¢é˜Ÿæˆ¿(MGM/MTC)({meeting_group_count}ä¸ªå›¢é˜Ÿ, å…±{total_meeting_rooms}é—´)åˆ†å¸ƒ: é‡‘é™µæ¥¼ {meeting_jinling_rooms} é—´, äºšå¤ªæ¥¼ {meeting_yatai_rooms} é—´"
                if meeting_other_rooms > 0: meeting_report += f", å…¶ä»–æ¥¼ {meeting_other_rooms} é—´"
                summary_parts.append(f"ï¼Œå…¶ä¸­{meeting_report}.")
            else:
                summary_parts.append("ï¼Œ(æ— ä¼šè®®/å…¬å¸å›¢é˜Ÿæˆ¿).")

            if total_gto_rooms > 0:
                gto_report = f"æ—…è¡Œç¤¾(GTO)æˆ¿({gto_group_count}ä¸ªå›¢é˜Ÿ, {total_gto_rooms}é—´, å…±{total_gto_guests}äºº)åˆ†å¸ƒ: é‡‘é™µæ¥¼ {gto_jinling_rooms} é—´, äºšå¤ªæ¥¼ {gto_yatai_rooms} é—´"
                if gto_other_rooms > 0: gto_report += f", å…¶ä»–æ¥¼ {gto_other_rooms} é—´"
                summary_parts.append(f" | {gto_report}.")
            else:
                summary_parts.append(" | (æ— GTOæ—…è¡Œç¤¾æˆ¿).")

            final_summary_lines.append("".join(summary_parts))

        except Exception as e:
            final_summary_lines.append(f"ã€{file_base_name}ã€‘å¤„ç†å¤±è´¥ï¼Œé”™è¯¯: {e}")

    return final_summary_lines, unknown_codes_collection

# ==============================================================================
# --- APP 1: OCR å·¥å…· (V9 - å…¨æ–°ç‰ˆ) ---
# ==============================================================================
def run_ocr_app():
    """åŒ…å«äº† OCR é”€å”®é€šçŸ¥ç”Ÿæˆå™¨çš„æ‰€æœ‰é€»è¾‘å’Œ UIã€‚"""

    # --- é…ç½®ä¿¡æ¯ ---
    TEAM_TYPE_MAP = { "CON": "ä¼šè®®å›¢", "FIT": "æ•£å®¢å›¢", "WA": "å©šå®´å›¢" }
    DEFAULT_TEAM_TYPE = "æ—…æ¸¸å›¢"
    ALL_ROOM_CODES = [
        "DETN", "DKN", "DQN", "DQS", "DSKN", "DSTN", "DTN", "EKN", "EKS", "ESN", "ESS",
        "ETN", "ETS", "FSN", "FSB", "FSC", "OTN", "PSA", "PSB", "RSN", "SKN",
        "SQN", "SQS", "SSN", "SSS", "STN", "STS", "JDEN", "JDKN", "JDKS", "JEKN",
        "JESN", "JESS", "JETN", "JETS", "JKN", "JLKN", "JTN", "JTS", "PSC", "PSD",
        "VCKN", "VCKD", "SITN", "JEN", "JIS", "JTIN"
    ]

    # --- OCR å¼•æ“å‡½æ•° (é˜¿é‡Œäº‘ç‰ˆ) ---
    def get_ocr_text_from_aliyun(image: Image.Image) -> str:
        if not ALIYUN_SDK_AVAILABLE:
            st.error("é”™è¯¯ï¼šé˜¿é‡Œäº‘ SDK æœªå®‰è£…ã€‚è¯·è¿è¡Œ 'pip install alibabacloud_ocr_api20210707' è¿›è¡Œå®‰è£…ã€‚")
            return None
        
        if "aliyun_credentials" not in st.secrets:
            st.error("é”™è¯¯ï¼šé˜¿é‡Œäº‘å‡­è¯æœªåœ¨ Streamlit çš„ Secrets ä¸­é…ç½®ã€‚è¯·å‚è€ƒä»£ç æ³¨é‡Šåˆ›å»º .streamlit/secrets.toml æ–‡ä»¶ã€‚")
            return None
        
        access_key_id = st.secrets.aliyun_credentials.get("access_key_id")
        access_key_secret = st.secrets.aliyun_credentials.get("access_key_secret")

        if not access_key_id or not access_key_secret:
            st.error("é”™è¯¯ï¼šé˜¿é‡Œäº‘ AccessKey ID æˆ– Secret æœªåœ¨ Secrets ä¸­æ­£ç¡®é…ç½®ã€‚")
            return None
            
        try:
            config = open_api_models.Config(
                access_key_id=access_key_id,
                access_key_secret=access_key_secret,
                endpoint='ocr-api.cn-hangzhou.aliyuncs.com'
            )
            client = OcrClient(config)

            buffered = io.BytesIO()
            if image.mode == 'RGBA':
                image = image.convert('RGB')
            
            image_format = "JPEG"
            image.save(buffered, format=image_format)
            buffered.seek(0)
            
            request = ocr_models.RecognizeGeneralRequest(body=buffered)
            response = client.recognize_general(request)

            if response.status_code == 200 and response.body and response.body.data:
                data = json.loads(response.body.data)
                return data.get('content', '')
            else:
                error_message = 'æ— è¯¦ç»†ä¿¡æ¯'
                if response.body and hasattr(response.body, 'message'):
                   error_message = response.body.message
                raise Exception(f"é˜¿é‡Œäº‘ OCR API è¿”å›é”™è¯¯: {error_message}")

        except Exception as e:
            st.error(f"è°ƒç”¨é˜¿é‡Œäº‘ OCR API å¤±è´¥: {e}")
            return None

    # --- ä¿¡æ¯æå–ä¸æ ¼å¼åŒ– ---
    def extract_booking_info(ocr_text: str):
        team_name_pattern = re.compile(r'((?:CON|FIT|WA)\d+\s*/\s*[\u4e00-\u9fa5\w]+)', re.IGNORECASE)
        date_pattern = re.compile(r'(\d{1,2}/\d{1,2})')

        team_name_match = team_name_pattern.search(ocr_text)
        if not team_name_match: return "é”™è¯¯ï¼šæ— æ³•è¯†åˆ«å‡ºå›¢é˜Ÿåç§°ã€‚"
        team_name = re.sub(r'\s*/\s*', '/', team_name_match.group(1).strip())

        all_dates = date_pattern.findall(ocr_text)
        unique_dates = sorted(list(set(all_dates)))
        if not unique_dates: return "é”™è¯¯ï¼šæ— æ³•è¯†åˆ«å‡ºæœ‰æ•ˆçš„æ—¥æœŸã€‚"
        arrival_date = unique_dates[0]
        departure_date = unique_dates[-1]

        room_codes_pattern_str = '|'.join(ALL_ROOM_CODES)
        room_finder_pattern = re.compile(f'({room_codes_pattern_str})\\s*(\\d+)', re.IGNORECASE)
        price_finder_pattern = re.compile(r'\b(\d+\.\d{2})\b')

        found_rooms = [(m.group(1).upper(), int(m.group(2)), m.span()) for m in room_finder_pattern.finditer(ocr_text)]
        found_prices = [(float(m.group(1)), m.span()) for m in price_finder_pattern.finditer(ocr_text)]

        room_details = []
        available_prices = list(found_prices)

        for room_type, num_rooms, room_span in found_rooms:
            best_price = None
            best_price_index = -1
            min_distance = float('inf')

            for i, (price_val, price_span) in enumerate(available_prices):
                if price_span[0] > room_span[1]:
                    distance = price_span[0] - room_span[1]
                    if distance < min_distance:
                        min_distance = distance
                        best_price = price_val
                        best_price_index = i
            
            if best_price is not None and best_price > 0:
                room_details.append((room_type, num_rooms, int(best_price)))
                if best_price_index != -1:
                    available_prices.pop(best_price_index)

        if not room_details:
            return f"æç¤ºï¼šæ‰¾åˆ°äº†å›¢é˜Ÿ {team_name}ï¼Œä½†æœªèƒ½è‡ªåŠ¨åŒ¹é…ä»»ä½•æœ‰æ•ˆçš„æˆ¿å‹å’Œä»·æ ¼ã€‚è¯·æ£€æŸ¥åŸå§‹æ–‡æœ¬å¹¶æ‰‹åŠ¨å¡«å†™ã€‚"

        team_prefix = team_name[:3].upper()
        team_type = TEAM_TYPE_MAP.get(team_prefix, DEFAULT_TEAM_TYPE)
        room_details.sort(key=lambda x: x[1])

        try:
            arr_month, arr_day = map(int, arrival_date.split('/'))
            dep_month, dep_day = map(int, departure_date.split('/'))
            formatted_arrival = f"{arr_month}æœˆ{arr_day}æ—¥"
            formatted_departure = f"{dep_month}æœˆ{dep_day}æ—¥"
        except (ValueError, IndexError):
            return "é”™è¯¯ï¼šæ—¥æœŸæ ¼å¼æ— æ³•è§£æã€‚"

        df = pd.DataFrame(room_details, columns=['æˆ¿å‹', 'æˆ¿æ•°', 'å®šä»·'])
        return {"team_name": team_name, "team_type": team_type, "arrival_date": formatted_arrival, "departure_date": formatted_departure, "room_dataframe": df}

    def format_notification_speech(team_name, team_type, arrival_date, departure_date, room_df):
        date_range_string = f"{arrival_date}è‡³{departure_date}"
        room_details = room_df.to_dict('records')
        formatted_rooms = [f"{item['æˆ¿æ•°']}é—´{item['æˆ¿å‹']}({item['å®šä»·']})" for item in room_details]
        room_string = " ".join(formatted_rooms) if formatted_rooms else "æ— æˆ¿é—´è¯¦æƒ…"
        return f"æ–°å¢{team_type} {team_name} {date_range_string} {room_string}ã€‚é”€å”®é€šçŸ¥"

    # --- Streamlit ä¸»åº”ç”¨ UI ---
    st.title("é‡‘é™µå·¥å…·ç®± - OCR å·¥å…·")
    
    st.markdown("""
    **å…¨æ–°å·¥ä½œæµ**ï¼š
    1.  **ä¸Šä¼ å›¾ç‰‡ï¼Œç‚¹å‡»æå–**ï¼šç¨‹åºå°†è°ƒç”¨é˜¿é‡Œäº‘ OCR å¹¶å°†**åŸå§‹è¯†åˆ«æ–‡æœ¬**æ˜¾ç¤ºåœ¨ä¸‹æ–¹ã€‚
    2.  **è‡ªåŠ¨å¡«å……ä¸äººå·¥ä¿®æ­£**ï¼šç¨‹åºä¼šå°è¯•è‡ªåŠ¨å¡«å……ç»“æ„åŒ–ä¿¡æ¯ã€‚æ‚¨å¯ä»¥**å‚ç…§åŸå§‹æ–‡æœ¬**ï¼Œç›´æ¥åœ¨è¡¨æ ¼ä¸­ä¿®æ”¹ï¼Œç¡®ä¿ä¿¡æ¯å®Œå…¨å‡†ç¡®ã€‚
    3.  **ç”Ÿæˆè¯æœ¯**ï¼šç¡®è®¤æ— è¯¯åï¼Œç”Ÿæˆæœ€ç»ˆè¯æœ¯ã€‚
    """)

    uploaded_file = st.file_uploader("ä¸Šä¼ å›¾ç‰‡æ–‡ä»¶", type=["png", "jpg", "jpeg", "bmp"], key="ocr_uploader")

    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        st.image(image, caption="ä¸Šä¼ çš„å›¾ç‰‡", width=300)

        if st.button("ä»å›¾ç‰‡æå–ä¿¡æ¯ (é˜¿é‡Œäº‘ OCR)"):
            # æ¸…ç†æ—§çš„çŠ¶æ€
            for key in ['raw_ocr_text', 'booking_info']:
                if key in st.session_state:
                    del st.session_state[key]
            
            with st.spinner('æ­£åœ¨è°ƒç”¨é˜¿é‡Œäº‘ OCR API è¯†åˆ«ä¸­...'):
                ocr_text = get_ocr_text_from_aliyun(image)
                if ocr_text:
                    st.session_state['raw_ocr_text'] = ocr_text
                    result = extract_booking_info(ocr_text)
                    if isinstance(result, str):
                        st.warning(f"è‡ªåŠ¨è§£ææç¤ºï¼š{result}")
                        st.info("è¯·å‚è€ƒä¸‹æ–¹è¯†åˆ«å‡ºçš„åŸå§‹æ–‡æœ¬ï¼Œæ‰‹åŠ¨å¡«å†™ä¿¡æ¯ã€‚")
                        empty_df = pd.DataFrame(columns=['æˆ¿å‹', 'æˆ¿æ•°', 'å®šä»·'])
                        st.session_state['booking_info'] = { "team_name": "", "team_type": DEFAULT_TEAM_TYPE, "arrival_date": "", "departure_date": "", "room_dataframe": empty_df }
                    else:
                        st.session_state['booking_info'] = result
                        st.success("ä¿¡æ¯æå–æˆåŠŸï¼è¯·åœ¨ä¸‹æ–¹æ ¸å¯¹å¹¶ç¼–è¾‘ã€‚")

    if 'booking_info' in st.session_state:
        info = st.session_state['booking_info']
        if 'raw_ocr_text' in st.session_state:
            st.markdown("---")
            st.subheader("åŸå§‹è¯†åˆ«ç»“æœ (ä¾›å‚è€ƒ)")
            st.text_area("æ‚¨å¯ä»¥ä»è¿™é‡Œå¤åˆ¶å†…å®¹æ¥ä¿®æ­£ä¸‹é¢çš„è¡¨æ ¼", st.session_state['raw_ocr_text'], height=200)
        st.markdown("---")
        st.subheader("æ ¸å¯¹ä¸ç¼–è¾‘ä¿¡æ¯")
        col1, col2, col3, col4 = st.columns(4)
        with col1: info['team_name'] = st.text_input("å›¢é˜Ÿåç§°", value=info['team_name'])
        with col2: info['team_type'] = st.selectbox("å›¢é˜Ÿç±»å‹", options=list(TEAM_TYPE_MAP.values()) + [DEFAULT_TEAM_TYPE], index=(list(TEAM_TYPE_MAP.values()) + [DEFAULT_TEAM_TYPE]).index(info['team_type']))
        with col3: arrival = st.text_input("åˆ°è¾¾æ—¥æœŸ", value=info['arrival_date'])
        with col4: departure = st.text_input("ç¦»å¼€æ—¥æœŸ", value=info['departure_date'])
        
        st.markdown("##### æˆ¿é—´è¯¦æƒ… (å¯ç›´æ¥åœ¨è¡¨æ ¼ä¸­ç¼–è¾‘)")
        edited_df = st.data_editor(info['room_dataframe'], num_rows="dynamic", use_container_width=True)
        
        if st.button("ç”Ÿæˆæœ€ç»ˆè¯æœ¯"):
            final_speech = format_notification_speech(info['team_name'], info['team_type'], arrival, departure, edited_df)
            st.subheader("ç”ŸæˆæˆåŠŸï¼")
            st.success(final_speech)
            st.code(final_speech, language=None)
            
# ==============================================================================
# --- APP 2: å¤šç»´å®¡æ ¸æ¯”å¯¹å¹³å° ---
# ==============================================================================
def run_comparison_app():
    """Contains all logic and UI for the Data Comparison Platform."""
    SESSION_DEFAULTS = {
        'df1': None, 'df2': None, 'df1_name': "", 'df2_name': "",
        'ran_comparison': False, 'common_rows': pd.DataFrame(),
        'matched_df': pd.DataFrame(), 'in_file1_only': pd.DataFrame(),
        'in_file2_only': pd.DataFrame(), 'compare_cols_keys': []
    }
    for key, value in SESSION_DEFAULTS.items():
        if key not in st.session_state:
            st.session_state[key] = value

    def forensic_clean_text(text):
        if not isinstance(text, str): return text
        try:
            cleaned_text = unicodedata.normalize('NFKC', text)
        except (TypeError, ValueError):
            return text
        cleaned_text = re.sub(r'[\u200B-\u200D\uFEFF\s\xa0]+', '', cleaned_text)
        return cleaned_text.strip()

    def process_and_standardize(df, mapping, case_insensitive=False, room_type_equivalents=None):
        if not mapping.get('name'):
            return pd.DataFrame()

        standard_df = pd.DataFrame()
        for col_key, col_name in mapping.items():
            if col_name and col_name in df.columns:
                standard_df[col_key] = df[col_name]

        def robust_date_parser(series):
            def process_date(date_str):
                if pd.isna(date_str): return pd.NaT
                date_str = str(date_str).strip()
                if re.match(r'^\d{1,2}/\d{1,2}', date_str):
                    date_part = date_str.split(' ')[0]
                    return f"2025-{date_part.replace('/', '-')}"
                return date_str
            return pd.to_datetime(series.apply(process_date), errors='coerce').dt.strftime('%Y-%m-%d')

        if 'start_date' in standard_df.columns:
            standard_df['start_date'] = robust_date_parser(standard_df['start_date'])
        if 'end_date' in standard_df.columns:
            standard_df['end_date'] = robust_date_parser(standard_df['end_date'])

        if 'room_type' in standard_df.columns:
            standard_df['room_type'] = standard_df['room_type'].astype(str).apply(forensic_clean_text)
            if room_type_equivalents:
                direct_map = {}
                for key, values in room_type_equivalents.items():
                    for value in values:
                        direct_map[forensic_clean_text(value)] = forensic_clean_text(key)
                standard_df['room_type'] = standard_df['room_type'].replace(direct_map)

        if 'price' in standard_df.columns:
            standard_df['price'] = pd.to_numeric(standard_df['price'].astype(str).str.strip(), errors='coerce')

        standard_df['name'] = standard_df['name'].astype(str).str.split(r'[ã€,ï¼Œ/]')
        standard_df = standard_df.explode('name')
        standard_df['name'] = standard_df['name'].apply(forensic_clean_text)

        if case_insensitive:
            standard_df['name'] = standard_df['name'].str.lower()

        standard_df = standard_df[standard_df['name'] != ''].dropna(subset=['name']).reset_index(drop=True)
        return standard_df

    def highlight_diff(row, col1, col2):
        style = 'background-color: #FFC7CE'
        if row.get(col1) != row.get(col2) and not (pd.isna(row.get(col1)) and pd.isna(row.get(col2))):
            return [style] * len(row)
        return [''] * len(row)

    st.title("é‡‘é™µå·¥å…·ç®± - æ¯”å¯¹å¹³å°")
    st.info("å…¨æ–°æ¨¡å¼ï¼šç»“æœä»¥ç‹¬ç«‹çš„æ ‡ç­¾é¡µå±•ç¤ºï¼Œå¹¶å†…ç½®æ™ºèƒ½æ—¥æœŸç»Ÿä¸€å¼•æ“ï¼Œæ¯”å¯¹æ›´ç²¾å‡†ï¼")

    st.header("ç¬¬ 1 æ­¥: ä¸Šä¼ æ–‡ä»¶")
    if st.button("æ¸…ç©ºå¹¶é‡ç½®"):
        for key in SESSION_DEFAULTS.keys():
            if key in st.session_state:
                del st.session_state[key]
        st.rerun()

    col1, col2 = st.columns(2)
    with col1:
        uploaded_file1 = st.file_uploader("ä¸Šä¼ åå•æ–‡ä»¶ 1", type=['csv', 'xlsx'], key="comp_uploader1")
        if uploaded_file1:
            st.session_state.df1 = pd.read_excel(uploaded_file1) if uploaded_file1.name.endswith('xlsx') else pd.read_csv(uploaded_file1)
            st.session_state.df1_name = uploaded_file1.name
    with col2:
        uploaded_file2 = st.file_uploader("ä¸Šä¼ åå•æ–‡ä»¶ 2", type=['csv', 'xlsx'], key="comp_uploader2")
        if uploaded_file2:
            st.session_state.df2 = pd.read_excel(uploaded_file2) if uploaded_file2.name.endswith('xlsx') else pd.read_csv(uploaded_file2)
            st.session_state.df2_name = uploaded_file2.name

    if st.session_state.df1 is not None and st.session_state.df2 is not None:
        st.header("ç¬¬ 2 æ­¥: é€‰æ‹©è¦æ¯”å¯¹çš„åˆ— (å§“åå¿…é€‰)")
        mapping = {'file1': {}, 'file2': {}}
        cols_to_map = ['name', 'start_date', 'end_date', 'room_type', 'price']
        col_names_zh = ['å§“å', 'å…¥ä½æ—¥æœŸ', 'ç¦»å¼€æ—¥æœŸ', 'æˆ¿å‹', 'æˆ¿ä»·']

        cols1, cols2 = st.columns(2)
        with cols1:
            st.subheader(f"æ–‡ä»¶ 1: {st.session_state.df1_name}")
            df1_cols = [None] + list(st.session_state.df1.columns)
            for key, name_zh in zip(cols_to_map, col_names_zh):
                mapping['file1'][key] = st.selectbox(f"{name_zh}", df1_cols, key=f'f1_{key}')
        with cols2:
            st.subheader(f"æ–‡ä»¶ 2: {st.session_state.df2_name}")
            df2_cols = [None] + list(st.session_state.df2.columns)
            for key, name_zh in zip(cols_to_map, col_names_zh):
                mapping['file2'][key] = st.selectbox(f"{name_zh}", df2_cols, key=f'f2_{key}')

        st.header("ç¬¬ 3 æ­¥: é…ç½®ä¸æ‰§è¡Œ")
        room_type_equivalents = {}
        if mapping['file1'].get('room_type') and mapping['file2'].get('room_type'):
            with st.expander("é«˜çº§åŠŸèƒ½ï¼šç»Ÿä¸€ä¸åŒåç§°çš„æˆ¿å‹ (ä¾‹å¦‚ï¼šè®©'å¤§åºŠæˆ¿'='King Room')"):
                unique_rooms1 = st.session_state.df1[mapping['file1']['room_type']].dropna().astype(str).unique()
                unique_rooms2 = list(st.session_state.df2[mapping['file2']['room_type']].dropna().astype(str).unique())
                for room1 in unique_rooms1:
                    room_type_equivalents[room1] = st.multiselect(f"æ–‡ä»¶1çš„â€œ{room1}â€ç­‰åŒäº:", unique_rooms2, key=f"map_{room1}")

        case_insensitive = st.checkbox("æ¯”å¯¹å§“åæ—¶å¿½ç•¥å¤§å°å†™/å…¨åŠè§’", True)

        if st.button("å¼€å§‹æ¯”å¯¹", type="primary"):
            if not mapping['file1'].get('name') or not mapping['file2'].get('name'):
                st.error("è¯·ç¡®ä¿ä¸¤è¾¹æ–‡ä»¶çš„â€œå§“åâ€éƒ½å·²æ­£ç¡®é€‰æ‹©ã€‚")
            else:
                with st.spinner('æ­£åœ¨æ‰§è¡Œç»ˆææ¯”å¯¹...'):
                    st.session_state.ran_comparison = True
                    std_df1 = process_and_standardize(st.session_state.df1.copy(), mapping['file1'], case_insensitive)
                    std_df2 = process_and_standardize(st.session_state.df2.copy(), mapping['file2'], case_insensitive, room_type_equivalents=room_type_equivalents)
                    merged_df = pd.merge(std_df1, std_df2, on='name', how='outer', suffixes=('_1', '_2'))
                    cols1_for_check = [f"{c}_1" for c in std_df1.columns if c != 'name']
                    cols2_for_check = [f"{c}_2" for c in std_df2.columns if c != 'name']
                    both_exist_mask = merged_df[cols1_for_check].notna().any(axis=1) & merged_df[cols2_for_check].notna().any(axis=1)
                    st.session_state.common_rows = merged_df[both_exist_mask].copy().reset_index(drop=True)
                    only_in_1_mask = merged_df[cols1_for_check].notna().any(axis=1) & merged_df[cols2_for_check].isna().all(axis=1)
                    st.session_state.in_file1_only = merged_df[only_in_1_mask].reset_index(drop=True)
                    only_in_2_mask = merged_df[cols1_for_check].isna().all(axis=1) & merged_df[cols2_for_check].notna().any(axis=1)
                    st.session_state.in_file2_only = merged_df[only_in_2_mask].reset_index(drop=True)
                    st.session_state.compare_cols_keys = [key for key in ['start_date', 'end_date', 'room_type', 'price'] if mapping['file1'].get(key) and mapping['file2'].get(key)]
                    if not st.session_state.common_rows.empty and st.session_state.compare_cols_keys:
                        condition = pd.Series(True, index=st.session_state.common_rows.index)
                        for key in st.session_state.compare_cols_keys:
                            condition &= (st.session_state.common_rows[f'{key}_1'] == st.session_state.common_rows[f'{key}_2']) | \
                                         (st.session_state.common_rows[f'{key}_1'].isna() & st.session_state.common_rows[f'{key}_2'].isna())
                        st.session_state.matched_df = st.session_state.common_rows[condition]
                    else:
                        st.session_state.matched_df = st.session_state.common_rows

        if st.session_state.ran_comparison:
            st.header("ç¬¬ 4 æ­¥: æŸ¥çœ‹æ¯”å¯¹ç»“æœ")
            tab_list = ["ç»“æœæ€»è§ˆ"]
            tab_name_map = {'start_date': "å…¥ä½æ—¥æœŸ", 'end_date': "ç¦»å¼€æ—¥æœŸ", 'room_type': "æˆ¿å‹", 'price': "æˆ¿ä»·"}
            for key in st.session_state.compare_cols_keys:
                tab_list.append(tab_name_map[key])
            tabs = st.tabs(tab_list)

            with tabs[0]:
                st.subheader("å®è§‚ç»Ÿè®¡")
                stat_cols = st.columns(3)
                matched_count = len(st.session_state.matched_df)
                only_1_count = len(st.session_state.in_file1_only)
                only_2_count = len(st.session_state.in_file2_only)
                stat_cols[0].metric("ä¿¡æ¯å®Œå…¨ä¸€è‡´", matched_count)
                stat_cols[1].metric(f"ä»… '{st.session_state.df1_name}' æœ‰", only_1_count)
                stat_cols[2].metric(f"ä»… '{st.session_state.df2_name}' æœ‰", only_2_count)

                st.subheader("äººå‘˜åå•è¯¦æƒ…")
                with st.expander(f"æŸ¥çœ‹ {matched_count} æ¡ä¿¡æ¯å®Œå…¨ä¸€è‡´çš„åå•"):
                    if not st.session_state.matched_df.empty:
                        st.dataframe(st.session_state.matched_df[['name']].rename(columns={'name': 'å§“å'}))
                    else:
                        st.write("æ²¡æœ‰ä¿¡æ¯å®Œå…¨ä¸€è‡´çš„äººå‘˜ã€‚")

                with st.expander(f"æŸ¥çœ‹ {only_1_count} æ¡ä»…å­˜åœ¨äº '{st.session_state.df1_name}' çš„åå•"):
                    if not st.session_state.in_file1_only.empty:
                        display_cols_1 = ['name'] + [c for c in cols_to_map if f"{c}_1" in st.session_state.in_file1_only.columns]
                        display_df_1 = st.session_state.in_file1_only[[f"{c}_1" if c != 'name' else 'name' for c in display_cols_1]]
                        display_df_1.columns = [col_names_zh[cols_to_map.index(c)] if c != 'name' else 'å§“å' for c in display_cols_1]
                        st.dataframe(display_df_1)
                    else:
                        st.write("æ²¡æœ‰äººå‘˜ã€‚")

                with st.expander(f"æŸ¥çœ‹ {only_2_count} æ¡ä»…å­˜åœ¨äº '{st.session_state.df2_name}' çš„åå•"):
                    if not st.session_state.in_file2_only.empty:
                        display_cols_2 = ['name'] + [c for c in cols_to_map if f"{c}_2" in st.session_state.in_file2_only.columns]
                        display_df_2 = st.session_state.in_file2_only[[f"{c}_2" if c != 'name' else 'name' for c in display_cols_2]]
                        display_df_2.columns = [col_names_zh[cols_to_map.index(c)] if c != 'name' else 'å§“å' for c in display_cols_2]
                        st.dataframe(display_df_2)
                    else:
                        st.write("æ²¡æœ‰äººå‘˜ã€‚")

            for i, key in enumerate(st.session_state.compare_cols_keys):
                with tabs[i+1]:
                    col1_name, col2_name = f'{key}_1', f'{key}_2'
                    display_name = col_names_zh[cols_to_map.index(key)]
                    st.subheader(f"ã€{display_name}ã€‘æ¯”å¯¹è¯¦æƒ…")
                    if not st.session_state.common_rows.empty:
                        compare_df = st.session_state.common_rows[['name', col1_name, col2_name]].copy()
                        compare_df.rename(columns={'name': 'å§“å', col1_name: f'æ–‡ä»¶1 - {display_name}', col2_name: f'æ–‡ä»¶2 - {display_name}'}, inplace=True)
                        styled_df = compare_df.style.apply(highlight_diff, col1=f'æ–‡ä»¶1 - {display_name}', col2=f'æ–‡ä»¶2 - {display_name}', axis=1)
                        st.dataframe(styled_df)
                    else:
                        st.info("ä¸¤ä¸ªæ–‡ä»¶ä¸­æ²¡æœ‰å…±åŒçš„äººå‘˜å¯ä¾›è¿›è¡Œç»†èŠ‚æ¯”å¯¹ã€‚")

        st.divider()
        st.header("åŸå§‹æ•°æ®é¢„è§ˆ")
        c1, c2 = st.columns(2)
        with c1:
            st.caption(f"æ–‡ä»¶ 1: {st.session_state.df1_name}")
            st.dataframe(st.session_state.df1)
        with c2:
            st.caption(f"æ–‡ä»¶ 2: {st.session_state.df2_name}")
            st.dataframe(st.session_state.df2)

# ==============================================================================
# --- APP 3: å›¢é˜Ÿåˆ°åº—ç»Ÿè®¡ ---
# ==============================================================================
def run_analyzer_app():
    st.title("ğŸ“ˆ å›¢é˜Ÿåˆ°åº—ç»Ÿè®¡")
    st.markdown("---å›¢é˜ŸæŠ¥è¡¨åˆ†æå·¥å…·---")

    uploaded_files = st.file_uploader("è¯·ä¸Šä¼ æ‚¨çš„ Excel æŠ¥å‘Šæ–‡ä»¶ (.xlsx)", type=["xlsx"], accept_multiple_files=True, key="analyzer_uploader")

    if uploaded_files:
        st.subheader("åˆ†æç»“æœ")
        
        temp_dir = "./temp_uploaded_files"
        os.makedirs(temp_dir, exist_ok=True)

        file_paths = []
        for uploaded_file in uploaded_files:
            temp_file_path = os.path.join(temp_dir, uploaded_file.name)
            with open(temp_file_path, "wb") as f:
                f.write(uploaded_file.getbuffer())
            file_paths.append(temp_file_path)

        desired_order = ["æ¬¡æ—¥åˆ°è¾¾", "æ¬¡æ—¥åœ¨ä½", "æ¬¡æ—¥ç¦»åº—", "åå¤©åˆ°è¾¾"]

        def sort_key(file_path):
            file_name = os.path.basename(file_path)
            for i, keyword in enumerate(desired_order):
                if keyword in file_name:
                    return i
            return len(desired_order) 

        file_paths.sort(key=sort_key)

        if st.button("å¼€å§‹åˆ†æ"):
            with st.spinner("æ­£åœ¨åˆ†æä¸­ï¼Œè¯·ç¨å€™..."):
                summaries, unknown_codes = analyze_reports_ultimate(file_paths)
            
            for summary in summaries:
                st.write(summary)

            if unknown_codes:
                st.subheader("ä¾¦æµ‹åˆ°çš„æœªçŸ¥æˆ¿å‹ä»£ç  (è¯·æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°è§„åˆ™)")
                for code, count in unknown_codes.items():
                    st.write(f"ä»£ç : '{code}' (å‡ºç°äº† {count} æ¬¡)")
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            for f_path in file_paths:
                try:
                    os.remove(f_path)
                except OSError as e:
                    st.warning(f"æ— æ³•åˆ é™¤ä¸´æ—¶æ–‡ä»¶ {f_path}: {e}")
            try:
                os.rmdir(temp_dir)
            except OSError as e:
                st.warning(f"æ— æ³•åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤¹ {temp_dir}: {e}")


    else:
        st.info("è¯·ä¸Šä¼ ä¸€ä¸ªæˆ–å¤šä¸ª Excel æ–‡ä»¶ä»¥å¼€å§‹åˆ†æã€‚")

    st.markdown("""
    --- 
    #### ä½¿ç”¨è¯´æ˜ï¼š
    1. ç‚¹å‡» "Browse files" ä¸Šä¼ æ‚¨çš„ Excel æŠ¥å‘Šã€‚å¯ä»¥åŒæ—¶ä¸Šä¼ å¤šä¸ªæ–‡ä»¶ã€‚
    2. æ–‡ä»¶ä¸Šä¼ åï¼Œç‚¹å‡» "å¼€å§‹åˆ†æ" æŒ‰é’®ã€‚
    3. åˆ†æç»“æœå°†æ˜¾ç¤ºåœ¨ä¸‹æ–¹ã€‚
    """)

# ==============================================================================
# --- APP 4: é…’åº—å…¥ä½æ•°æ®åˆ†æåº”ç”¨ ---
# ==============================================================================
@st.cache_data
def process_data(uploaded_file):
    df = pd.read_excel(uploaded_file)
    df.columns = [str(col).strip().upper() for col in df.columns]
    required_cols = ['çŠ¶æ€', 'æˆ¿ç±»', 'æˆ¿æ•°', 'åˆ°è¾¾', 'ç¦»å¼€', 'æˆ¿ä»·', 'å¸‚åœºç ']
    rename_map = {'ROOM CATEGORY': 'æˆ¿ç±»', 'ROOMS': 'æˆ¿æ•°', 'ARRIVAL': 'åˆ°è¾¾', 'DEPARTURE': 'ç¦»å¼€', 'RATE': 'æˆ¿ä»·', 'MARKET': 'å¸‚åœºç ', 'STATUS': 'çŠ¶æ€'}
    df.rename(columns=rename_map, inplace=True)
    missing_cols = [col for col in required_cols if col not in df.columns]
    if missing_cols:
        st.error(f"ä¸Šä¼ çš„æ–‡ä»¶ç¼ºå°‘ä»¥ä¸‹å¿…è¦çš„åˆ—: {', '.join(missing_cols)}ã€‚è¯·æ£€æŸ¥æ–‡ä»¶ã€‚")
        return None, None
    df['åˆ°è¾¾_str'] = df['åˆ°è¾¾'].astype(str).str.split(' ').str[0]
    df['ç¦»å¼€_str'] = df['ç¦»å¼€'].astype(str).str.split(' ').str[0]
    df['åˆ°è¾¾'] = pd.to_datetime(df['åˆ°è¾¾_str'], format='%y/%m/%d', errors='coerce')
    df['ç¦»å¼€'] = pd.to_datetime(df['ç¦»å¼€_str'], format='%y/%m/%d', errors='coerce')
    df['æˆ¿ä»·'] = pd.to_numeric(df['æˆ¿ä»·'], errors='coerce')
    df['æˆ¿æ•°'] = pd.to_numeric(df['æˆ¿æ•°'], errors='coerce')
    df['å¸‚åœºç '] = df['å¸‚åœºç '].astype(str)
    df.dropna(subset=['åˆ°è¾¾', 'ç¦»å¼€', 'æˆ¿ä»·', 'æˆ¿æ•°', 'æˆ¿ç±»'], inplace=True)
    df['æˆ¿æ•°'] = df['æˆ¿æ•°'].astype(int)
    jinling_rooms = ['DETN', 'DKN', 'DQN', 'DQS', 'DSKN', 'DSTN', 'DTN', 'EKN', 'EKS', 'ESN', 'ESS', 'ETN', 'ETS', 'FSB', 'FSC', 'FSN', 'OTN', 'PSA', 'PSB', 'RSN', 'SKN', 'SQN', 'SQS', 'SSN', 'SSS', 'STN', 'STS']
    yatal_rooms = ['JDEN', 'JDKN', 'JDKS', 'JEKN', 'JESN', 'JESS', 'JETN', 'JETS', 'JKN', 'JLKN', 'JTN', 'JTS', 'PSC', 'PSD', 'VCKD', 'VCKN']
    room_to_building = {code: "é‡‘é™µæ¥¼" for code in jinling_rooms}
    room_to_building.update({code: "äºšå¤ªæ¥¼" for code in yatal_rooms})
    df = df[df['æˆ¿ç±»'].isin(jinling_rooms + yatal_rooms)].copy()
    df['æ¥¼å±‚'] = df['æˆ¿ç±»'].map(room_to_building)
    df['å…¥ä½å¤©æ•°'] = (df['ç¦»å¼€'].dt.normalize() - df['åˆ°è¾¾'].dt.normalize()).dt.days
    df_for_arrivals = df.copy()
    df_for_stays = df[(df['å…¥ä½å¤©æ•°'] > 0) & (df['çŠ¶æ€'].isin(['R', 'I']))].copy()
    if df_for_stays.empty:
        return df_for_arrivals, pd.DataFrame()
    df_repeated = df_for_stays.loc[df_for_stays.index.repeat(df_for_stays['å…¥ä½å¤©æ•°'])]
    date_offset = df_repeated.groupby(level=0).cumcount()
    df_repeated['ä½åº—æ—¥'] = df_repeated['åˆ°è¾¾'].dt.normalize() + pd.to_timedelta(date_offset, unit='D')
    expanded_df = df_repeated.drop(columns=['åˆ°è¾¾', 'ç¦»å¼€', 'å…¥ä½å¤©æ•°']).reset_index(drop=True)
    return df_for_arrivals, expanded_df.copy()


def run_data_analysis_app():
    st.title("é‡‘é™µå·¥å…·ç®± - æ•°æ®åˆ†æé©¾é©¶èˆ±")
    uploaded_file = st.file_uploader("ä¸Šä¼ æ‚¨çš„Excelæ–‡ä»¶", type=["xlsx", "xls"], key="data_analysis_uploader")
    if not uploaded_file:
        st.info("è¯·ä¸Šä¼ æ‚¨çš„Excelæ–‡ä»¶ä»¥å¼€å§‹åˆ†æã€‚")
        return
    try:
        original_df, expanded_df = process_data(uploaded_file)
        if original_df is None: return
        if original_df.empty:
            st.warning("ä¸Šä¼ çš„æ–‡ä»¶ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æ•°æ®è®°å½•ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶å†…å®¹å’Œæ ¼å¼ã€‚")
            return
        st.success(f"æ–‡ä»¶ '{uploaded_file.name}' ä¸Šä¼ å¹¶å¤„ç†æˆåŠŸï¼")
        st.header("1. æ¯æ—¥åˆ°åº—/ç¦»åº—æˆ¿æ•°ç»Ÿè®¡")
        with st.expander("ç‚¹å‡»å±•å¼€æˆ–æŠ˜å ", expanded=True):
            st.subheader("åˆ°åº—æˆ¿æ•°ç»Ÿè®¡")
            all_statuses = sorted(original_df['çŠ¶æ€'].unique())
            selected_arrival_statuses = st.multiselect("é€‰æ‹©åˆ°åº—çŠ¶æ€", options=all_statuses, default=['R'])
            arrival_dates_str = st.text_input("è¾“å…¥åˆ°åº—æ—¥æœŸ (ç”¨é€—å·åˆ†éš”, æ ¼å¼: YYYY/MM/DD)", pd.to_datetime(original_df['åˆ°è¾¾'].min()).strftime('%Y/%m/%d') if not original_df.empty else "")
            arrival_summary = pd.DataFrame()
            if arrival_dates_str and selected_arrival_statuses:
                try:
                    date_strings = [d.strip() for d in arrival_dates_str.split(',') if d.strip()]
                    selected_arrival_dates = [pd.to_datetime(d, format='%Y/%m/%d').date() for d in date_strings]
                    arrival_df = original_df[(original_df['çŠ¶æ€'].isin(selected_arrival_statuses)) & (original_df['åˆ°è¾¾'].dt.date.isin(selected_arrival_dates))].copy()
                    if not arrival_df.empty:
                        arrival_summary = arrival_df.groupby([arrival_df['åˆ°è¾¾'].dt.date, 'æ¥¼å±‚'])['æˆ¿æ•°'].sum().unstack(fill_value=0)
                        arrival_summary.index.name = "åˆ°åº—æ—¥æœŸ"
                        st.dataframe(arrival_summary)
                    else:
                        st.warning(f"åœ¨æ‰€é€‰æ—¥æœŸå’ŒçŠ¶æ€å†…æ²¡æœ‰æ‰¾åˆ°åˆ°åº—è®°å½•ã€‚")
                except ValueError:
                    st.error("åˆ°åº—æ—¥æœŸæ ¼å¼ä¸æ­£ç¡®ï¼Œè¯·è¾“å…¥ YYYY/MM/DD æ ¼å¼ã€‚")
            st.subheader("ç¦»åº—æˆ¿æ•°ç»Ÿè®¡")
            selected_departure_statuses = st.multiselect("é€‰æ‹©ç¦»åº—çŠ¶æ€", options=all_statuses, default=['R', 'S', 'I', 'O'])
            departure_dates_str = st.text_input("è¾“å…¥ç¦»åº—æ—¥æœŸ (ç”¨é€—å·åˆ†éš”, æ ¼å¼: YYYY/MM/DD)", pd.to_datetime(original_df['ç¦»å¼€'].min()).strftime('%Y/%m/%d') if not original_df.empty else "")
            departure_summary = pd.DataFrame()
            if departure_dates_str and selected_departure_statuses:
                try:
                    date_strings = [d.strip() for d in departure_dates_str.split(',') if d.strip()]
                    selected_departure_dates = [pd.to_datetime(d, format='%Y/%m/%d').date() for d in date_strings]
                    departure_df = original_df[(original_df['çŠ¶æ€'].isin(selected_departure_statuses)) & (original_df['ç¦»å¼€'].dt.date.isin(selected_departure_dates))].copy()
                    if not departure_df.empty:
                        departure_summary = departure_df.groupby([departure_df['ç¦»å¼€'].dt.date, 'æ¥¼å±‚'])['æˆ¿æ•°'].sum().unstack(fill_value=0)
                        departure_summary.index.name = "ç¦»åº—æ—¥æœŸ"
                        st.dataframe(departure_summary)
                    else:
                        st.warning(f"åœ¨æ‰€é€‰æ—¥æœŸå’ŒçŠ¶æ€å†…æ²¡æœ‰æ‰¾åˆ°ç¦»åº—è®°å½•ã€‚")
                except ValueError:
                    st.error("ç¦»åº—æ—¥æœŸæ ¼å¼ä¸æ­£ç¡®ï¼Œè¯·è¾“å…¥ YYYY/MM/DD æ ¼å¼ã€‚")
            if not arrival_summary.empty or not departure_summary.empty:
                df_to_download = {}
                if not arrival_summary.empty: df_to_download["åˆ°åº—ç»Ÿè®¡"] = arrival_summary
                if not departure_summary.empty: df_to_download["ç¦»åº—ç»Ÿè®¡"] = departure_summary
                excel_data = to_excel(df_to_download)
                st.download_button(label="ä¸‹è½½ç»Ÿè®¡ç»“æœä¸º Excel", data=excel_data, file_name="arrival_departure_summary.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
        st.markdown("---")
        st.header("2. æ¯æ—¥åœ¨ä½æˆ¿é—´æŒ‰ä»·æ ¼åˆ†å¸ƒçŸ©é˜µ")
        with st.expander("ç‚¹å‡»å±•å¼€æˆ–æŠ˜å ", expanded=True):
            default_stay_date = ""
            if not expanded_df.empty and 'ä½åº—æ—¥' in expanded_df.columns:
                   default_stay_date = pd.to_datetime(expanded_df['ä½åº—æ—¥'].min()).strftime('%Y/%m/%d')
            stay_dates_str = st.text_input("è¾“å…¥ä½åº—æ—¥æœŸ (ç”¨é€—å·åˆ†éš”, æ ¼å¼: YYYY/MM/DD)", default_stay_date)
            selected_stay_dates = []
            if stay_dates_str:
                try:
                    stay_date_strings = [d.strip() for d in stay_dates_str.split(',') if d.strip()]
                    selected_stay_dates = [pd.to_datetime(d, format='%Y/%m/%d').date() for d in stay_date_strings]
                except ValueError:
                    st.error("ä½åº—æ—¥æœŸæ ¼å¼ä¸æ­£ç¡®ï¼Œè¯·è¾“å…¥ YYYY/MM/DD æ ¼å¼ã€‚")
                    st.stop()
            all_market_codes = sorted(original_df['å¸‚åœºç '].dropna().unique())
            selected_market_codes = st.multiselect("é€‰æ‹©å¸‚åœºç  (å¯å¤šé€‰)", options=all_market_codes, default=all_market_codes)
            st.subheader("è‡ªå®šä¹‰ä»·æ ¼åŒºé—´")
            col1, col2 = st.columns(2)
            with col1:
                price_bins_jinling_str = st.text_input("é‡‘é™µæ¥¼ä»·æ ¼åŒºé—´", "<401, 401-480, 481-500, 501-550, 551-599, >599")
            with col2:
                price_bins_yatal_str = st.text_input("äºšå¤ªæ¥¼ä»·æ ¼åŒºé—´", "<501, 501-600, 601-699, 700-749, 750-799, >799")
            def parse_price_bins(price_bins_str):
                if not price_bins_str.strip(): return None, None
                intervals = []
                for item in price_bins_str.split(','):
                    item = item.strip()
                    if item.startswith('<'):
                        upper = int(re.search(r'\d+', item).group())
                        intervals.append({'lower': float('-inf'), 'upper': upper, 'label': f'< {upper}'})
                    elif item.startswith('>'):
                        lower = int(re.search(r'\d+', item).group())
                        intervals.append({'lower': lower, 'upper': float('inf'), 'label': f'> {lower}'})
                    elif '-' in item:
                        parts = item.split('-')
                        lower, upper = int(parts[0]), int(parts[1])
                        if lower >= upper: raise ValueError(f"ä»·æ ¼åŒºé—´ '{item}' æ— æ•ˆï¼šä¸‹é™å¿…é¡»å°äºä¸Šé™ã€‚")
                        intervals.append({'lower': lower, 'upper': upper, 'label': f'{lower}-{upper}'})
                    else: raise ValueError(f"æ— æ³•è§£æåŒºé—´ '{item}'")
                intervals.sort(key=lambda x: x['lower'])
                bins = [d['lower'] for d in intervals] + [intervals[-1]['upper']]
                labels = [d['label'] for d in intervals]
                return bins, labels
            try:
                bins_jinling, labels_jinling = parse_price_bins(price_bins_jinling_str)
                bins_yatal, labels_yatal = parse_price_bins(price_bins_yatal_str)
            except (ValueError, IndexError, AttributeError) as e:
                st.error(f"ä»·æ ¼åŒºé—´æ ¼å¼ä¸æ­£ç¡®ã€‚é”™è¯¯: {e}")
                st.stop()
            dfs_to_download_matrix = {}
            if selected_stay_dates and selected_market_codes:
                matrix_df = expanded_df[(expanded_df['ä½åº—æ—¥'].dt.date.isin(selected_stay_dates)) & (expanded_df['å¸‚åœºç '].isin(selected_market_codes))].copy()
                if not matrix_df.empty:
                    buildings = sorted(matrix_df['æ¥¼å±‚'].unique())
                    for building in buildings:
                        st.subheader(f"{building} - åœ¨ä½æˆ¿é—´åˆ†å¸ƒ")
                        building_df = matrix_df[matrix_df['æ¥¼å±‚'] == building]
                        bins, labels = (bins_jinling, labels_jinling) if building == "é‡‘é™µæ¥¼" else (bins_yatal, labels_yatal)
                        if not building_df.empty and bins and labels:
                            building_df['ä»·æ ¼åŒºé—´'] = pd.cut(building_df['æˆ¿ä»·'], bins=bins, labels=labels, right=True, include_lowest=True)
                            pivot_table = pd.pivot_table(building_df.dropna(subset=['ä»·æ ¼åŒºé—´']), index=building_df['ä½åº—æ—¥'].dt.date, columns='ä»·æ ¼åŒºé—´', values='æˆ¿æ•°', aggfunc='sum', fill_value=0)
                            if not pivot_table.empty:
                                pivot_table['æ¯æ—¥æ€»è®¡'] = pivot_table.sum(axis=1)
                                st.dataframe(pivot_table.sort_index())
                                dfs_to_download_matrix[f"{building}_åœ¨ä½åˆ†å¸ƒ"] = pivot_table
                            else:
                               st.info(f"åœ¨ {building} ä¸­ï¼Œæ‰€é€‰æ¡ä»¶ä¸‹çš„æ‰€æœ‰æˆ¿ä»·éƒ½ä¸åœ¨æ‚¨å®šä¹‰çš„ä»·æ ¼åŒºé—´å†…ã€‚")
                        else:
                            st.info(f"åœ¨ {building} ä¸­ï¼Œæ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ‰€é€‰æ¡ä»¶çš„åœ¨ä½è®°å½•æˆ–æœªè®¾ç½®ä»·æ ¼åŒºé—´ã€‚")
                else:
                    st.warning(f"åœ¨æ‰€é€‰æ—¥æœŸå’Œå¸‚åœºç èŒƒå›´å†…æ²¡æœ‰æ‰¾åˆ°åœ¨ä½è®°å½•ã€‚")
            if dfs_to_download_matrix:
                excel_data_matrix = to_excel(dfs_to_download_matrix)
                st.download_button(label="ä¸‹è½½ä»·æ ¼åˆ†å¸ƒçŸ©é˜µä¸º Excel", data=excel_data_matrix, file_name="price_matrix_summary.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
    except Exception as e:
        st.error(f"å¤„ç†æ•°æ®æˆ–ç”ŸæˆæŠ¥å‘Šæ—¶å‘ç”Ÿæ„å¤–é”™è¯¯ã€‚è¯·æ£€æŸ¥æ‚¨çš„Excelæ–‡ä»¶æ ¼å¼æ˜¯å¦æ­£ç¡®ã€‚")
        st.error(f"æŠ€æœ¯ç»†èŠ‚: {e}")
        st.code(f"Traceback: {traceback.format_exc()}")


# ==============================================================================
# --- APP 5: æ—©ç­è¯æœ¯ç”Ÿæˆå™¨ ---
# ==============================================================================
def run_morning_briefing_app():
    st.title("é‡‘é™µå·¥å…·ç®± - æ—©ç­è¯æœ¯ç”Ÿæˆå™¨")
    st.subheader("æ•°æ®è¾“å…¥")
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("#### é‡‘é™µæ¥¼æ•°æ®")
        jl_occupancy = st.number_input("æ˜¨æ—¥å‡ºç§Ÿç‡ (%)", key="jl_occ", format="%.1f", value=82.4)
        jl_revenue = st.number_input("æ”¶å…¥ (å…ƒ)", key="jl_rev", format="%.1f", value=247173.4)
        jl_adr = st.number_input("å¹³å‡æˆ¿ä»· (å…ƒ)", key="jl_adr", format="%.1f", value=550.5)
        jl_guests = st.number_input("æ€»äººæ•°", key="jl_guests", value=673)
        jl_jinhaiwan = st.number_input("é‡‘æµ·æ¹¾äººæ•°", key="jl_jinhaiwan", value=572)
    with col2:
        st.markdown("#### äºšå¤ªæ¥¼æ•°æ®")
        yt_occupancy = st.number_input("æ˜¨æ—¥å‡ºç§Ÿç‡ (%)", key="yt_occ", format="%.1f", value=83.9)
        yt_revenue = st.number_input("æ”¶å…¥ (å…ƒ)", key="yt_rev", format="%.1f", value=232385.5)
        yt_adr = st.number_input("å¹³å‡æˆ¿ä»· (å…ƒ)", key="yt_adr", format="%.1f", value=719.5)
        yt_guests = st.number_input("æ€»äººæ•°", key="yt_guests", value=485)
        yt_jia = st.number_input("å®¶é¤å…äººæ•°", key="yt_jia", value=323)
    st.markdown("---")
    st.subheader("å…¶ä»–æ•°æ®")
    col3, col4 = st.columns(2)
    with col3:
        onbook_jl = st.number_input("ç›®å‰On Bookå‡ºç§Ÿç‡ - é‡‘é™µæ¥¼ (%)", key="ob_jl", format="%.1f", value=65.5)
        onbook_yt = st.number_input("ç›®å‰On Bookå‡ºç§Ÿç‡ - äºšå¤ªæ¥¼ (%)", key="ob_yt", format="%.1f", value=57.7)
    with col4:
        mini_prog_yesterday = st.number_input("å°ç¨‹åºè®¢æˆ¿ - æ˜¨æ—¥ (é—´å¤œ)", key="mp_yest", value=26)
        mini_prog_today = st.number_input("å°ç¨‹åºè®¢æˆ¿ - ä»Šæ—¥ (é—´å¤œ)", key="mp_today", value=19)
    if st.button("ç”Ÿæˆè¯æœ¯"):
        briefing = (f"æ˜¨æ—¥é‡‘é™µæ¥¼å‡ºç§Ÿç‡{jl_occupancy}%ï¼Œæ”¶å…¥{jl_revenue}å…ƒï¼Œå¹³å‡æˆ¿ä»·{jl_adr}å…ƒï¼Œæ€»äººæ•°{jl_guests}äººï¼Œé‡‘æµ·æ¹¾{jl_jinhaiwan}äººã€‚" f"äºšå¤ªå•†åŠ¡æ¥¼å‡ºç‡{yt_occupancy}%ï¼Œæ”¶å…¥{yt_revenue}å…ƒï¼Œå¹³å‡æˆ¿ä»·{yt_adr}å…ƒï¼Œæ€»äººæ•°{yt_guests}äººï¼Œå®¶é¤å…{yt_jia}äººã€‚" f"ç›®å‰on bookå‡ºç§Ÿç‡é‡‘é™µæ¥¼{onbook_jl}%ï¼Œäºšå¤ªå•†åŠ¡æ¥¼{onbook_yt}%ã€‚" f"å°ç¨‹åºè®¢æˆ¿æ˜¨æ—¥{mini_prog_yesterday}é—´å¤œï¼Œä»Šæ—¥{mini_prog_today}é—´å¤œã€‚")
        st.subheader("ç”Ÿæˆçš„è¯æœ¯")
        st.success(briefing)
        st.code(briefing)

# ==============================================================================
# --- APP 6: å¸¸ç”¨è¯æœ¯å¤åˆ¶å™¨ ---
# ==============================================================================
def run_common_phrases_app():
    st.title("é‡‘é™µå·¥å…·ç®± - å¸¸ç”¨è¯æœ¯")
    phrases = ["CA RM TO CREDIT FM", "å…é¢„ä»˜,æˆ¿è´¹åŠ3000å…ƒä»¥å†…æ‚è´¹è½¬æ·˜å® FM", "æˆ¿è´¹è½¬æºç¨‹å®ç¿ FM", "æˆ¿ä»·ä¿å¯†,æˆ¿è´¹è½¬åä¸º FM", "æˆ¿è´¹è½¬æ·˜å® FM", "CA RM TO å…°è‰³(109789242)é‡‘é™µå¡ FM", "CA RM TO AGODA FM", "CA RM TO CREDIT CARD FM XX-XX/XX(å¡å·/æœ‰æ•ˆæœŸXX/XX)", "æˆ¿è´¹è½¬å¾®ä¿¡ FM", "æˆ¿è´¹é¢„ä»˜æ‚è´¹è‡ªç†FM"]
    st.subheader("ç‚¹å‡»å³ä¸Šè§’å¤åˆ¶å›¾æ ‡å³å¯å¤åˆ¶è¯æœ¯")
    for phrase in phrases:
        st.code(phrase, language=None)


# ==============================================================================
# --- APP 7: æ¯æ—¥å‡ºç§Ÿç‡å¯¹ç…§è¡¨ ---
# ==============================================================================
def run_daily_occupancy_app():
    st.title("é‡‘é™µå·¥å…·ç®± - æ¯æ—¥å‡ºç§Ÿç‡å¯¹ç…§è¡¨")
    st.info("è®¡ç®—è§„åˆ™: å½“æ—¥é¢„è®¡(A), å½“æ—¥å®é™…(C), å½“æ—¥å¢åŠ ç‡(C-A) | å‘¨ä¸€é¢„è®¡(E), å½“æ—¥å®é™…(C), å¢åŠ ç™¾åˆ†ç‡(C-E)")

    def create_and_display_table(building_name):
        st.subheader(f"{building_name} - æ•°æ®è¾“å…¥")
        
        today = date.today()
        days = [(today + timedelta(days=i)) for i in range(7)]
        weekdays_zh = ["å‘¨ä¸€", "å‘¨äºŒ", "å‘¨ä¸‰", "å‘¨å››", "å‘¨äº”", "å‘¨å…­", "å‘¨æ—¥"]
        
        initial_data = {
            "æ—¥æœŸ": [d.strftime("%m/%d") for d in days],
            "æ˜ŸæœŸ": [weekdays_zh[d.weekday()] for d in days],
            "å½“æ—¥é¢„è®¡ (%)": [0.0] * 7,
            "å½“æ—¥å®é™… (%)": [0.0] * 7,
            "å‘¨ä¸€é¢„è®¡ (%)": [0.0] * 7,
            "å¹³å‡æˆ¿ä»·": [0.0] * 7
        }
        input_df = pd.DataFrame(initial_data)
        
        edited_df = st.data_editor(
            input_df, 
            key=f"editor_{building_name}", 
            num_rows="fixed",
            use_container_width=True,
            column_config={
                "å½“æ—¥é¢„è®¡ (%)": st.column_config.NumberColumn(format="%.2f%%"),
                "å½“æ—¥å®é™… (%)": st.column_config.NumberColumn(format="%.2f%%"),
                "å‘¨ä¸€é¢„è®¡ (%)": st.column_config.NumberColumn(format="%.2f%%"),
                "å¹³å‡æˆ¿ä»·": st.column_config.NumberColumn("å¹³å‡æˆ¿ä»· (å…ƒ)", format="%.2f"),
            }
        )
        return edited_df

    tabs = st.tabs(["é‡‘é™µæ¥¼", "äºšå¤ªæ¥¼"])
    with tabs[0]:
        jl_df = create_and_display_table("é‡‘é™µæ¥¼")
    with tabs[1]:
        yt_df = create_and_display_table("äºšå¤ªæ¥¼")

    st.markdown("---")
    st.header("è®¡ç®—ç»“æœ")

    if st.button("è®¡ç®—å¹¶ç”ŸæˆæŠ¥å‘Š"):
        for df, name in [(jl_df, "é‡‘é™µæ¥¼"), (yt_df, "äºšå¤ªæ¥¼")]:
            st.subheader(f"{name} - è®¡ç®—ç»“æœ")
            try:
                result_df = df.copy()
                # ä½¿ç”¨æ–°çš„åˆ—åè¿›è¡Œè®¡ç®—
                result_df["å½“æ—¥å¢åŠ ç‡ (%)"] = result_df["å½“æ—¥å®é™… (%)"] - result_df["å½“æ—¥é¢„è®¡ (%)"]
                result_df["å¢åŠ ç™¾åˆ†ç‡ (%)"] = result_df["å½“æ—¥å®é™… (%)"] - result_df["å‘¨ä¸€é¢„è®¡ (%)"]
                
                # å®šä¹‰æœ€ç»ˆå±•ç¤ºçš„åˆ—å’Œé¡ºåº
                display_columns = [
                    "æ—¥æœŸ", "æ˜ŸæœŸ", 
                    "å½“æ—¥é¢„è®¡ (%)", "å½“æ—¥å®é™… (%)", "å½“æ—¥å¢åŠ ç‡ (%)", 
                    "å‘¨ä¸€é¢„è®¡ (%)", "å¢åŠ ç™¾åˆ†ç‡ (%)", "å¹³å‡æˆ¿ä»·"
                ]
                result_df_display = result_df[display_columns]

                # æ ¼å¼åŒ–è¾“å‡º
                st.dataframe(result_df_display.style.format({
                    "å½“æ—¥é¢„è®¡ (%)": "{:.2f}%", 
                    "å½“æ—¥å®é™… (%)": "{:.2f}%", 
                    "å½“æ—¥å¢åŠ ç‡ (%)": "{:+.2f}%",
                    "å‘¨ä¸€é¢„è®¡ (%)": "{:.2f}%", 
                    "å¢åŠ ç™¾åˆ†ç‡ (%)": "{:+.2f}%", 
                    "å¹³å‡æˆ¿ä»·": "{:.2f}"
                }))
                
                st.markdown("---")
                st.subheader(f"{name} - æœ¬å‘¨æ€»è®¡")
                
                total_actual = result_df['å½“æ—¥å®é™… (%)'].sum()
                total_forecast = result_df['å½“æ—¥é¢„è®¡ (%)'].sum()
                total_increase = total_actual - total_forecast
                
                col1, col2, col3 = st.columns(3)
                col1.metric("æœ¬å‘¨å®é™… (åŠ æ€»)", f"{total_actual:.2f}%")
                col2.metric("æœ¬å‘¨é¢„æµ‹ (åŠ æ€»)", f"{total_forecast:.2f}%")
                col3.metric("å®é™…å¢åŠ  (ç‚¹æ•°)", f"{total_increase:+.2f}")

            except (ValueError, IndexError, KeyError) as e:
                st.error(f"åœ¨è®¡ç®— {name} æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")

# ==============================================================================
# --- å…¨å±€å‡½æ•°å’Œä¸»åº”ç”¨è·¯ç”±å™¨ ---
# ==============================================================================
@st.cache_data
def to_excel(df_dict):
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        for sheet_name, df in df_dict.items():
            df.to_excel(writer, sheet_name=sheet_name)
    processed_data = output.getvalue()
    return processed_data
    
def check_password():
    """è¿”å› True å¦‚æœç”¨æˆ·å·²ç™»å½•, å¦åˆ™è¿”å› False."""
    def login_form():
        with st.form("Credentials"):
            st.text_input("ç”¨æˆ·å", key="username")
            st.text_input("å¯†ç ", type="password", key="password")
            st.form_submit_button("ç™»å½•", on_click=password_entered)

    def password_entered():
        app_username = st.secrets.app_credentials.get("username")
        app_password = st.secrets.app_credentials.get("password")
        if st.session_state.get("username") == app_username and st.session_state.get("password") == app_password:
            st.session_state["password_correct"] = True
            if "password" in st.session_state: del st.session_state["password"]
            if "username" in st.session_state: del st.session_state["username"]
        else:
            st.session_state["password_correct"] = False

    if "app_credentials" not in st.secrets or not st.secrets.app_credentials.get("username") or not st.secrets.app_credentials.get("password"):
        st.error("é”™è¯¯ï¼šåº”ç”¨çš„ç”¨æˆ·åæˆ–å¯†ç æœªåœ¨ Streamlit Secrets ä¸­æ­£ç¡®é…ç½®ã€‚")
        return False

    if st.session_state.get("password_correct", False):
        return True

    login_form()
    if "password_correct" in st.session_state and not st.session_state.password_correct:
        st.error("ç”¨æˆ·åæˆ–å¯†ç ä¸æ­£ç¡®ã€‚")
    return False


# --- ä¸»åº”ç”¨è·¯ç”±å™¨ ---
st.set_page_config(layout="wide", page_title="é‡‘é™µå·¥å…·ç®±")

if check_password():
    with st.sidebar:
        app_choice = option_menu(
            menu_title="é‡‘é™µå·¥å…·ç®±",
            options=["OCR å·¥å…·", "æ¯æ—¥å‡ºç§Ÿç‡å¯¹ç…§è¡¨", "æ¯”å¯¹å¹³å°", "å›¢é˜Ÿåˆ°åº—ç»Ÿè®¡", "æ•°æ®åˆ†æ", "è¯æœ¯ç”Ÿæˆå™¨", "å¸¸ç”¨è¯æœ¯"],
            icons=["camera-reels-fill", "calculator", "kanban", "clipboard-data", "graph-up-arrow", "blockquote-left", "card-text"],
            menu_icon="tools",
            default_index=0,
        )

    st.sidebar.markdown("---")
    st.sidebar.info("è¿™æ˜¯ä¸€ä¸ªå°†å¤šä¸ªå·¥å…·é›†æˆåˆ°ä¸€èµ·çš„åº”ç”¨ã€‚")

    if app_choice == "OCR å·¥å…·":
        run_ocr_app()
    elif app_choice == "æ¯æ—¥å‡ºç§Ÿç‡å¯¹ç…§è¡¨":
        run_daily_occupancy_app()
    elif app_choice == "æ¯”å¯¹å¹³å°":
        run_comparison_app()
    elif app_choice == "å›¢é˜Ÿåˆ°åº—ç»Ÿè®¡":
        run_analyzer_app()
    elif app_choice == "æ•°æ®åˆ†æ":
        run_data_analysis_app()
    elif app_choice == "è¯æœ¯ç”Ÿæˆå™¨":
        run_morning_briefing_app()
    elif app_choice == "å¸¸ç”¨è¯æœ¯":
        run_common_phrases_app()

